[I 2024-06-06 10:29:27,260] A new study created in memory with name: no-name-b11bfb3f-fda3-449c-9887-7b06d50db318
[I 2024-06-06 10:31:28,387] Trial 0 finished with value: 0.9144329896907217 and parameters: {'booster': 'gbtree', 'eta': 0.14189419674806433, 'learning_rate': 0.2589375048207179, 'n_estimators': 564, 'max_depth': 17, 'min_child_weight': 7, 'subsample': 0.6645589275017594, 'colsample_bytree': 0.5538174608177917, 'gamma': 0.7471232595842495, 'lambda': 2.0015913233305955}. Best is trial 0 with value: 0.9144329896907217.
[I 2024-06-06 10:31:44,652] Trial 1 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.2881197140996814, 'learning_rate': 0.07121217307740275, 'n_estimators': 1008, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.8244832409915792, 'colsample_bytree': 0.7688166503451705, 'gamma': 0.7751567512605257, 'lambda': 1.3364181470358205}. Best is trial 1 with value: 0.9219931271477665.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:50] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:31:50,608] Trial 2 finished with value: 0.804810996563574 and parameters: {'booster': 'gblinear', 'eta': 0.3442201633061135, 'learning_rate': 0.24039353100246538, 'n_estimators': 571, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9484407115017177, 'colsample_bytree': 0.6559810726781623, 'gamma': 0.26184944754221384, 'lambda': 1.694701890420601}. Best is trial 1 with value: 0.9219931271477665.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:50] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:51] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:58] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:31:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:32:06,800] Trial 3 finished with value: 0.804810996563574 and parameters: {'booster': 'gblinear', 'eta': 0.8237714075188457, 'learning_rate': 0.17416602003831283, 'n_estimators': 1653, 'max_depth': 18, 'min_child_weight': 5, 'subsample': 0.9336915343007295, 'colsample_bytree': 0.8181659257147115, 'gamma': 0.8762701644831472, 'lambda': 1.797510865704998}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:32:19,690] Trial 4 finished with value: 0.9206185567010311 and parameters: {'booster': 'gbtree', 'eta': 0.50784956341214, 'learning_rate': 0.08700235582437547, 'n_estimators': 751, 'max_depth': 12, 'min_child_weight': 8, 'subsample': 0.8113078042662338, 'colsample_bytree': 0.8330007124136622, 'gamma': 0.7059291248590626, 'lambda': 1.9306481306286558}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:32:30,672] Trial 5 finished with value: 0.9103092783505157 and parameters: {'booster': 'gbtree', 'eta': 0.641401582539787, 'learning_rate': 0.2212864364319498, 'n_estimators': 687, 'max_depth': 17, 'min_child_weight': 7, 'subsample': 0.5411332894182681, 'colsample_bytree': 0.9877913404489671, 'gamma': 0.05480575329694648, 'lambda': 2.9867162088555563}. Best is trial 1 with value: 0.9219931271477665.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:34] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:35] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:35] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:36] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:37] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:38] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:39] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:39] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:40] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:41] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:32:42,189] Trial 6 finished with value: 0.8075601374570449 and parameters: {'booster': 'gblinear', 'eta': 0.48630971569623294, 'learning_rate': 0.0913438015350187, 'n_estimators': 1107, 'max_depth': 16, 'min_child_weight': 6, 'subsample': 0.6372643383094885, 'colsample_bytree': 0.6129606689139124, 'gamma': 0.9196596905465144, 'lambda': 1.2598369159311582}. Best is trial 1 with value: 0.9219931271477665.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:50] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:51] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:32:55,854] Trial 7 finished with value: 0.8075601374570449 and parameters: {'booster': 'gblinear', 'eta': 0.1617983411527928, 'learning_rate': 0.03931593986944901, 'n_estimators': 1356, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.8525225282885127, 'colsample_bytree': 0.5795620297634129, 'gamma': 0.3443972422600431, 'lambda': 1.2270604866216916}. Best is trial 1 with value: 0.9219931271477665.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:56] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:58] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:32:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:33:05,432] Trial 8 finished with value: 0.8044673539518903 and parameters: {'booster': 'gblinear', 'eta': 0.39241556541267286, 'learning_rate': 0.16518389183482118, 'n_estimators': 960, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.7878580224493383, 'colsample_bytree': 0.6500714783687905, 'gamma': 0.7879476149750664, 'lambda': 2.0374804631696772}. Best is trial 1 with value: 0.9219931271477665.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:33:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:33:19,391] Trial 9 finished with value: 0.8089347079037803 and parameters: {'booster': 'gblinear', 'eta': 0.528337199009657, 'learning_rate': 0.1303796036038127, 'n_estimators': 1386, 'max_depth': 14, 'min_child_weight': 4, 'subsample': 0.7937543662349267, 'colsample_bytree': 0.7703340072173943, 'gamma': 0.6456497359699527, 'lambda': 0.8647987263095354}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:34:14,514] Trial 10 finished with value: 0.9171821305841926 and parameters: {'booster': 'gbtree', 'eta': 0.01852403218363352, 'learning_rate': 0.00972866361633093, 'n_estimators': 1943, 'max_depth': 20, 'min_child_weight': 1, 'subsample': 0.9899536947777379, 'colsample_bytree': 0.5020135558928676, 'gamma': 0.9971507081798223, 'lambda': 0.6323951854067928}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:34:29,172] Trial 11 finished with value: 0.9195876288659794 and parameters: {'booster': 'gbtree', 'eta': 0.9244537078829079, 'learning_rate': 0.0746619827575575, 'n_estimators': 811, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.8372165187502066, 'colsample_bytree': 0.8491719182250865, 'gamma': 0.5970870643040194, 'lambda': 2.4348066910351247}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:34:38,609] Trial 12 finished with value: 0.9058419243986255 and parameters: {'booster': 'gbtree', 'eta': 0.30762101471046677, 'learning_rate': 0.09153594696168992, 'n_estimators': 844, 'max_depth': 1, 'min_child_weight': 9, 'subsample': 0.720555376460294, 'colsample_bytree': 0.7180590187800471, 'gamma': 0.5501031046423469, 'lambda': 1.3641040107874376}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:34:53,593] Trial 13 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.6552746697551562, 'learning_rate': 0.05209042314825257, 'n_estimators': 751, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8845329089964236, 'colsample_bytree': 0.8793345831787218, 'gamma': 0.7450325742897786, 'lambda': 1.529018513026941}. Best is trial 1 with value: 0.9219931271477665.
[I 2024-06-06 10:35:40,184] Trial 14 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.685633783714476, 'learning_rate': 0.009601281635417382, 'n_estimators': 1003, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8726768566422265, 'colsample_bytree': 0.9099295117724246, 'gamma': 0.811457858353875, 'lambda': 0.9598608903837699}. Best is trial 14 with value: 0.9223367697594503.
[I 2024-06-06 10:36:35,634] Trial 15 finished with value: 0.9202749140893473 and parameters: {'booster': 'gbtree', 'eta': 0.7777563831948752, 'learning_rate': 0.006603550242234996, 'n_estimators': 1071, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.9061914174796124, 'colsample_bytree': 0.9385874525978604, 'gamma': 0.8484108186258004, 'lambda': 0.9726973161478907}. Best is trial 14 with value: 0.9223367697594503.
[I 2024-06-06 10:36:50,414] Trial 16 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.9274225769035029, 'learning_rate': 0.03531920705793476, 'n_estimators': 946, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.8762742645055599, 'colsample_bytree': 0.9030674409617284, 'gamma': 0.9974852633046516, 'lambda': 1.0062831730150346}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:37:12,256] Trial 17 finished with value: 0.9082474226804126 and parameters: {'booster': 'gbtree', 'eta': 0.982206573721464, 'learning_rate': 0.007552340283315976, 'n_estimators': 917, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.9999192491200026, 'colsample_bytree': 0.916004613487939, 'gamma': 0.9966859038882734, 'lambda': 0.5175257086679572}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:37:34,128] Trial 18 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.8578497456363576, 'learning_rate': 0.0378616744953514, 'n_estimators': 1211, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.8817127764006737, 'colsample_bytree': 0.9881936405950953, 'gamma': 0.8990882511051101, 'lambda': 0.8995108787695268}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:37:44,262] Trial 19 finished with value: 0.9089347079037802 and parameters: {'booster': 'gbtree', 'eta': 0.7469146062681493, 'learning_rate': 0.13580047862768668, 'n_estimators': 900, 'max_depth': 1, 'min_child_weight': 4, 'subsample': 0.756734773455368, 'colsample_bytree': 0.9126544630620915, 'gamma': 0.48068294418454716, 'lambda': 0.9839140457536045}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:38:02,989] Trial 20 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.9765348582651345, 'learning_rate': 0.03369446390224334, 'n_estimators': 1185, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9346327301164412, 'colsample_bytree': 0.9475730726877754, 'gamma': 0.9984775853027416, 'lambda': 0.6572862598333509}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:38:22,798] Trial 21 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.910998894726988, 'learning_rate': 0.0306778694737196, 'n_estimators': 1215, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9328807087668289, 'colsample_bytree': 0.9523924181431408, 'gamma': 0.9879175871057577, 'lambda': 0.7369054526691128}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:40:04,617] Trial 22 finished with value: 0.8969072164948455 and parameters: {'booster': 'gbtree', 'eta': 0.9668703133563586, 'learning_rate': 0.001365601033188224, 'n_estimators': 1079, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8672305373410474, 'colsample_bytree': 0.8822900418773549, 'gamma': 0.8625915225349354, 'lambda': 0.5367576267185231}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:40:20,861] Trial 23 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.999966196154553, 'learning_rate': 0.05944027733469483, 'n_estimators': 953, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.9135071368354488, 'colsample_bytree': 0.9649272581204028, 'gamma': 0.9314759307335689, 'lambda': 1.1072763993985024}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:40:32,494] Trial 24 finished with value: 0.918556701030928 and parameters: {'booster': 'gbtree', 'eta': 0.9908167017445323, 'learning_rate': 0.06192892436576411, 'n_estimators': 895, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.9612686745117851, 'colsample_bytree': 0.9565850176708917, 'gamma': 0.9304453235487121, 'lambda': 0.7283382162286947}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:40:48,492] Trial 25 finished with value: 0.9178694158075603 and parameters: {'booster': 'gbtree', 'eta': 0.8637452097055749, 'learning_rate': 0.10775851473967037, 'n_estimators': 1186, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.9197516429610577, 'colsample_bytree': 0.9956949213215066, 'gamma': 0.9316151263899121, 'lambda': 1.094878307829709}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:41:11,128] Trial 26 finished with value: 0.9199312714776634 and parameters: {'booster': 'gbtree', 'eta': 0.9036852989642822, 'learning_rate': 0.046512037165961584, 'n_estimators': 1410, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9745886119995368, 'colsample_bytree': 0.9464792058338586, 'gamma': 0.8400757564410294, 'lambda': 1.1068716162335621}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:41:27,034] Trial 27 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.996272175852328, 'learning_rate': 0.03023968582151512, 'n_estimators': 957, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9091641544787242, 'colsample_bytree': 0.8678169146775792, 'gamma': 0.9898281428091431, 'lambda': 0.7607704632061305}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:41:39,330] Trial 28 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.8052516939585921, 'learning_rate': 0.030370415128044947, 'n_estimators': 644, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.951839162698124, 'colsample_bytree': 0.8635581622698119, 'gamma': 0.9915880162427642, 'lambda': 0.7095293826998976}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:42:07,769] Trial 29 finished with value: 0.9147766323024056 and parameters: {'booster': 'gbtree', 'eta': 0.8356398885936679, 'learning_rate': 0.024920192880477282, 'n_estimators': 614, 'max_depth': 2, 'min_child_weight': 6, 'subsample': 0.8923932786691191, 'colsample_bytree': 0.814891234503078, 'gamma': 0.7001641412709432, 'lambda': 0.7890410558478412}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:42:18,406] Trial 30 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7810974390645327, 'learning_rate': 0.05630244032448165, 'n_estimators': 508, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.9494352872589283, 'colsample_bytree': 0.8652701219366349, 'gamma': 0.8164028839359885, 'lambda': 0.512919628954331}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:42:28,991] Trial 31 finished with value: 0.9202749140893473 and parameters: {'booster': 'gbtree', 'eta': 0.7764211073797457, 'learning_rate': 0.054159078567278744, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.9715709769477621, 'colsample_bytree': 0.8680882887167585, 'gamma': 0.8234450160261279, 'lambda': 0.5098538485038634}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:42:40,527] Trial 32 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.8967527504385391, 'learning_rate': 0.02568042236526584, 'n_estimators': 514, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.9563523203516453, 'colsample_bytree': 0.7956998784664613, 'gamma': 0.9355661506437641, 'lambda': 0.752025337352463}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:42:49,385] Trial 33 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.8151796550976962, 'learning_rate': 0.07801056888571087, 'n_estimators': 596, 'max_depth': 2, 'min_child_weight': 8, 'subsample': 0.836299849521681, 'colsample_bytree': 0.8709286462082513, 'gamma': 0.7663348168918431, 'lambda': 0.673867825989057}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:43:00,690] Trial 34 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.7218551430431117, 'learning_rate': 0.06718456577271666, 'n_estimators': 652, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9082798670836103, 'colsample_bytree': 0.8545917011988985, 'gamma': 0.8743401570182715, 'lambda': 0.8488400215922696}. Best is trial 16 with value: 0.9250859106529211.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:43:06,647] Trial 35 finished with value: 0.8120274914089349 and parameters: {'booster': 'gblinear', 'eta': 0.9233701334490433, 'learning_rate': 0.024177007644600707, 'n_estimators': 550, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.931592395524971, 'colsample_bytree': 0.8323760969192499, 'gamma': 0.8890563400620629, 'lambda': 0.6147697898819241}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:43:12,907] Trial 36 finished with value: 0.8886597938144332 and parameters: {'booster': 'gbtree', 'eta': 0.8158293201667359, 'learning_rate': 0.04886895833470015, 'n_estimators': 545, 'max_depth': 1, 'min_child_weight': 5, 'subsample': 0.953786443735901, 'colsample_bytree': 0.8939271328572715, 'gamma': 0.9641298120751516, 'lambda': 0.8281405595313289}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:43:23,877] Trial 37 finished with value: 0.9178694158075603 and parameters: {'booster': 'gbtree', 'eta': 0.8592618578660659, 'learning_rate': 0.06852435318785544, 'n_estimators': 670, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.9983919029100963, 'colsample_bytree': 0.7968728110396113, 'gamma': 0.8879094104253462, 'lambda': 0.5879899680820393}. Best is trial 16 with value: 0.9250859106529211.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:43:31,789] Trial 38 finished with value: 0.8079037800687288 and parameters: {'booster': 'gblinear', 'eta': 0.5990495414797493, 'learning_rate': 0.2966428221694881, 'n_estimators': 744, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8630334706977911, 'colsample_bytree': 0.8424156793064459, 'gamma': 0.8106769165347398, 'lambda': 1.060801797680924}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:43:41,678] Trial 39 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.7445463323886246, 'learning_rate': 0.10405704007431346, 'n_estimators': 610, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8953249570617047, 'colsample_bytree': 0.8960683281150507, 'gamma': 0.9457514070114508, 'lambda': 0.8347005349990381}. Best is trial 16 with value: 0.9250859106529211.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:41] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:43:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:44:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:44:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:44:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:44:07,679] Trial 40 finished with value: 0.8123711340206188 and parameters: {'booster': 'gblinear', 'eta': 0.8000110823990495, 'learning_rate': 0.051691622076358835, 'n_estimators': 581, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.9453951066862055, 'colsample_bytree': 0.8549726686247514, 'gamma': 0.743277867543728, 'lambda': 0.5094736397171756}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:44:20,699] Trial 41 finished with value: 0.9199312714776634 and parameters: {'booster': 'gbtree', 'eta': 0.9324436654197297, 'learning_rate': 0.034177354501023785, 'n_estimators': 699, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.9363161249500918, 'colsample_bytree': 0.9336956737196763, 'gamma': 0.9991519744344862, 'lambda': 0.6820898581131523}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:44:37,693] Trial 42 finished with value: 0.9202749140893473 and parameters: {'booster': 'gbtree', 'eta': 0.9519338692973724, 'learning_rate': 0.01782716976658577, 'n_estimators': 810, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.9716307708590219, 'colsample_bytree': 0.9216972635514786, 'gamma': 0.9601073077969826, 'lambda': 0.66419929255583}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:44:52,273] Trial 43 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.8811500895878385, 'learning_rate': 0.03763439569425035, 'n_estimators': 1025, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.9179519615687419, 'colsample_bytree': 0.897472558053569, 'gamma': 0.9058595267325208, 'lambda': 0.9147542606464271}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:45:10,688] Trial 44 finished with value: 0.9195876288659796 and parameters: {'booster': 'gbtree', 'eta': 0.9581636311899444, 'learning_rate': 0.02007594139999099, 'n_estimators': 642, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.8414121195438413, 'colsample_bytree': 0.9715966425167603, 'gamma': 0.9946849096671894, 'lambda': 0.7384003971677559}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:45:21,333] Trial 45 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.9975546052430401, 'learning_rate': 0.03840399613156729, 'n_estimators': 532, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.942242709033675, 'colsample_bytree': 0.927817929303967, 'gamma': 0.8541033427330462, 'lambda': 1.21973996120732}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:45:27,530] Trial 46 finished with value: 0.8996563573883163 and parameters: {'booster': 'gbtree', 'eta': 0.848580307335858, 'learning_rate': 0.08394159967412251, 'n_estimators': 540, 'max_depth': 1, 'min_child_weight': 7, 'subsample': 0.976971130626562, 'colsample_bytree': 0.8816638217236441, 'gamma': 0.8457682364569062, 'lambda': 1.246149357276438}. Best is trial 16 with value: 0.9250859106529211.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:45:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:45:33,568] Trial 47 finished with value: 0.8068728522336772 and parameters: {'booster': 'gblinear', 'eta': 0.9318864283347449, 'learning_rate': 0.06752769448564898, 'n_estimators': 568, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8692670520989616, 'colsample_bytree': 0.9252566258091878, 'gamma': 0.7956187020504732, 'lambda': 1.3646610275718922}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:45:41,848] Trial 48 finished with value: 0.914089347079038 and parameters: {'booster': 'gbtree', 'eta': 0.8792618987053055, 'learning_rate': 0.04088979553077064, 'n_estimators': 512, 'max_depth': 2, 'min_child_weight': 9, 'subsample': 0.890669108603869, 'colsample_bytree': 0.8258556187920024, 'gamma': 0.8915366017078077, 'lambda': 1.0279578628257435}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:46:06,917] Trial 49 finished with value: 0.9161512027491411 and parameters: {'booster': 'gbtree', 'eta': 0.8104777092391988, 'learning_rate': 0.013263517604273807, 'n_estimators': 572, 'max_depth': 16, 'min_child_weight': 6, 'subsample': 0.949832063493348, 'colsample_bytree': 0.860347976577456, 'gamma': 0.9597432492462274, 'lambda': 1.2168197015468665}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:46:20,969] Trial 50 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.9381056307507085, 'learning_rate': 0.04391011627096776, 'n_estimators': 638, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.8207971306115386, 'colsample_bytree': 0.7366094331545858, 'gamma': 0.8552062680124235, 'lambda': 0.9371644733720281}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:46:58,333] Trial 51 finished with value: 0.8759450171821308 and parameters: {'booster': 'gbtree', 'eta': 0.9886674166233888, 'learning_rate': 0.0011062463014054197, 'n_estimators': 531, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.9260181358045466, 'colsample_bytree': 0.9363231614146879, 'gamma': 0.9669925460966274, 'lambda': 0.6334642320023091}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:47:11,544] Trial 52 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.9981190757142654, 'learning_rate': 0.03394844638477537, 'n_estimators': 698, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9042928289939397, 'colsample_bytree': 0.9088802241786983, 'gamma': 0.926685727112076, 'lambda': 0.8071780921389}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:47:28,379] Trial 53 finished with value: 0.9195876288659796 and parameters: {'booster': 'gbtree', 'eta': 0.902624312135215, 'learning_rate': 0.013790847030098044, 'n_estimators': 711, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.9067873373247457, 'colsample_bytree': 0.8989428944111981, 'gamma': 0.9111977738206202, 'lambda': 0.871825587018499}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:47:40,177] Trial 54 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.9995373002257745, 'learning_rate': 0.05586573772650105, 'n_estimators': 614, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8469051920129295, 'colsample_bytree': 0.9152351914565734, 'gamma': 0.7799389165245867, 'lambda': 1.004739443429524}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:47:58,779] Trial 55 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.944795627457059, 'learning_rate': 0.029906484539139012, 'n_estimators': 816, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.9844866052733767, 'colsample_bytree': 0.8769675204261339, 'gamma': 0.9110349594257766, 'lambda': 0.7892162839729345}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:48:05,456] Trial 56 finished with value: 0.8862542955326462 and parameters: {'booster': 'gbtree', 'eta': 0.9547587014146302, 'learning_rate': 0.04365263018176777, 'n_estimators': 586, 'max_depth': 1, 'min_child_weight': 10, 'subsample': 0.8796225701948022, 'colsample_bytree': 0.8416001785528338, 'gamma': 0.8677836857141523, 'lambda': 0.9216422943540625}. Best is trial 16 with value: 0.9250859106529211.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:48:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:48:10,941] Trial 57 finished with value: 0.8113402061855672 and parameters: {'booster': 'gblinear', 'eta': 0.8895637323364298, 'learning_rate': 0.07513601287233604, 'n_estimators': 525, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.947176656475462, 'colsample_bytree': 0.903529418432904, 'gamma': 0.8173721291867828, 'lambda': 0.6025004234704483}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:48:27,542] Trial 58 finished with value: 0.9199312714776634 and parameters: {'booster': 'gbtree', 'eta': 0.8528847113043783, 'learning_rate': 0.017481751418023397, 'n_estimators': 501, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.9001412117297638, 'colsample_bytree': 0.9675672988704279, 'gamma': 0.9510912084452008, 'lambda': 0.7789727734589161}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:48:36,474] Trial 59 finished with value: 0.9189003436426119 and parameters: {'booster': 'gbtree', 'eta': 0.9591102969838625, 'learning_rate': 0.03130988150178412, 'n_estimators': 551, 'max_depth': 2, 'min_child_weight': 1, 'subsample': 0.8576371579488118, 'colsample_bytree': 0.9245149997381754, 'gamma': 0.9239105397394709, 'lambda': 0.5723234966161779}. Best is trial 16 with value: 0.9250859106529211.
[I 2024-06-06 10:48:49,315] Trial 60 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.9961352537138181, 'learning_rate': 0.06011582208841541, 'n_estimators': 670, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.9229434908935089, 'colsample_bytree': 0.8835130466107475, 'gamma': 0.8401766649269728, 'lambda': 1.1541519626710959}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:49:02,686] Trial 61 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.9843684820598068, 'learning_rate': 0.05349823078137711, 'n_estimators': 675, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.923793168929667, 'colsample_bytree': 0.867140418744839, 'gamma': 0.8405229283042265, 'lambda': 1.121146889143377}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:49:15,389] Trial 62 finished with value: 0.9158075601374572 and parameters: {'booster': 'gbtree', 'eta': 0.9164097683294553, 'learning_rate': 0.06241030259855488, 'n_estimators': 723, 'max_depth': 14, 'min_child_weight': 7, 'subsample': 0.959862593893792, 'colsample_bytree': 0.8914601991754767, 'gamma': 0.965300994342674, 'lambda': 0.9738550777288122}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:49:31,965] Trial 63 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.998991729482225, 'learning_rate': 0.041904449347966465, 'n_estimators': 768, 'max_depth': 12, 'min_child_weight': 8, 'subsample': 0.9100250203841278, 'colsample_bytree': 0.9139595684899783, 'gamma': 0.8804956326004492, 'lambda': 1.4516426490340213}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:49:47,112] Trial 64 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.8968893014993384, 'learning_rate': 0.02666218549719654, 'n_estimators': 688, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.8803890823246885, 'colsample_bytree': 0.8807721138423132, 'gamma': 0.6969777789949835, 'lambda': 0.8717259562279931}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:50:29,694] Trial 65 finished with value: 0.9144329896907217 and parameters: {'booster': 'gbtree', 'eta': 0.9647983018097392, 'learning_rate': 0.006602005601015204, 'n_estimators': 858, 'max_depth': 20, 'min_child_weight': 6, 'subsample': 0.9880793720282178, 'colsample_bytree': 0.9429752739239181, 'gamma': 0.9289717256117209, 'lambda': 1.1514951591984597}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:50:40,039] Trial 66 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.8446753944043582, 'learning_rate': 0.08193425247126684, 'n_estimators': 638, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.9350884901379454, 'colsample_bytree': 0.857134294148825, 'gamma': 0.9764331271123976, 'lambda': 1.0383693134463288}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:50:58,808] Trial 67 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.9199163801809445, 'learning_rate': 0.03632883752431223, 'n_estimators': 951, 'max_depth': 18, 'min_child_weight': 6, 'subsample': 0.9665651404707037, 'colsample_bytree': 0.8417404110140052, 'gamma': 0.8190342760097322, 'lambda': 0.7325922466182248}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:51:09,752] Trial 68 finished with value: 0.9192439862542956 and parameters: {'booster': 'gbtree', 'eta': 0.8754593577575068, 'learning_rate': 0.059071243372569, 'n_estimators': 771, 'max_depth': 2, 'min_child_weight': 9, 'subsample': 0.8980520389736042, 'colsample_bytree': 0.8679586968897967, 'gamma': 0.8788162787936971, 'lambda': 1.2947188126853475}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:51:22,730] Trial 69 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.9726835868930509, 'learning_rate': 0.04808389131167157, 'n_estimators': 599, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.9425638106378623, 'colsample_bytree': 0.978945321704928, 'gamma': 0.7480615378494117, 'lambda': 1.1821232937108321}. Best is trial 60 with value: 0.9257731958762888.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:51:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:51:28,778] Trial 70 finished with value: 0.8079037800687288 and parameters: {'booster': 'gblinear', 'eta': 0.7796279009149477, 'learning_rate': 0.07190378182882401, 'n_estimators': 559, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9219659355192222, 'colsample_bytree': 0.9558350475015158, 'gamma': 0.9086509781957339, 'lambda': 1.060254152583683}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:51:51,301] Trial 71 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.9843213594217213, 'learning_rate': 0.02137827468177365, 'n_estimators': 773, 'max_depth': 13, 'min_child_weight': 8, 'subsample': 0.913392160083484, 'colsample_bytree': 0.9148226878649753, 'gamma': 0.8716529573054591, 'lambda': 1.4212181815588494}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:52:07,232] Trial 72 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.9965913832033396, 'learning_rate': 0.038791540014061696, 'n_estimators': 718, 'max_depth': 11, 'min_child_weight': 7, 'subsample': 0.902828913473014, 'colsample_bytree': 0.912783673927382, 'gamma': 0.9463798312207867, 'lambda': 1.5131632556929986}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:52:25,093] Trial 73 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.9352755927649002, 'learning_rate': 0.031799788084377105, 'n_estimators': 721, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8754649871802703, 'colsample_bytree': 0.8832589810870716, 'gamma': 0.9380236705913757, 'lambda': 1.5690514106462117}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:52:38,393] Trial 74 finished with value: 0.9199312714776634 and parameters: {'booster': 'gbtree', 'eta': 0.9646826860986226, 'learning_rate': 0.04897743740780351, 'n_estimators': 665, 'max_depth': 11, 'min_child_weight': 7, 'subsample': 0.9556224792301155, 'colsample_bytree': 0.9355135556338768, 'gamma': 0.9906347626801919, 'lambda': 1.292056993105024}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:52:50,623] Trial 75 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.8970376613081061, 'learning_rate': 0.06081429232970797, 'n_estimators': 621, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.8886128392663589, 'colsample_bytree': 0.9041018343900528, 'gamma': 0.9370101968302361, 'lambda': 1.1946572219079992}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:53:14,690] Trial 76 finished with value: 0.9178694158075603 and parameters: {'booster': 'gbtree', 'eta': 0.9216697580614036, 'learning_rate': 0.02153456536279673, 'n_estimators': 691, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.937834140886156, 'colsample_bytree': 0.887939163741023, 'gamma': 0.9992696833921614, 'lambda': 0.701782936419242}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:53:25,242] Trial 77 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.9982949774622556, 'learning_rate': 0.04071256366010213, 'n_estimators': 588, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9243390477365607, 'colsample_bytree': 0.9068109928362504, 'gamma': 0.9581794105852013, 'lambda': 0.8131064984615277}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:53:32,657] Trial 78 finished with value: 0.9206185567010311 and parameters: {'booster': 'gbtree', 'eta': 0.9491218092527042, 'learning_rate': 0.09057141714381092, 'n_estimators': 531, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9789623700498205, 'colsample_bytree': 0.8177666967236041, 'gamma': 0.9581068089447664, 'lambda': 0.9287272422402386}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:53:46,752] Trial 79 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.8321408377394575, 'learning_rate': 0.04122165128451513, 'n_estimators': 562, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.962676127873934, 'colsample_bytree': 0.9525803767919708, 'gamma': 0.9739204247795727, 'lambda': 0.5869845628098299}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:53:56,168] Trial 80 finished with value: 0.8972508591065294 and parameters: {'booster': 'gbtree', 'eta': 0.9683809715757169, 'learning_rate': 0.011586735023520534, 'n_estimators': 584, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.9263634856178569, 'colsample_bytree': 0.8527491907473608, 'gamma': 0.8397737456882365, 'lambda': 0.9831820102492075}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:54:09,954] Trial 81 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.9973164552365714, 'learning_rate': 0.035254471935603715, 'n_estimators': 662, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.9002238707990218, 'colsample_bytree': 0.9254777102043978, 'gamma': 0.9018535754504052, 'lambda': 0.8175667704264744}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:54:23,717] Trial 82 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.8681444071806961, 'learning_rate': 0.026571451231602494, 'n_estimators': 655, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8622228327065283, 'colsample_bytree': 0.8714672296974812, 'gamma': 0.9006121092916627, 'lambda': 0.6948594599273697}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:54:31,163] Trial 83 finished with value: 0.8783505154639177 and parameters: {'booster': 'gbtree', 'eta': 0.9350461808395291, 'learning_rate': 0.025979274383307237, 'n_estimators': 644, 'max_depth': 1, 'min_child_weight': 5, 'subsample': 0.8635521037528653, 'colsample_bytree': 0.9242275808489346, 'gamma': 0.9009649819261603, 'lambda': 0.8634981013343904}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:54:45,633] Trial 84 finished with value: 0.9202749140893473 and parameters: {'booster': 'gbtree', 'eta': 0.8766181022185546, 'learning_rate': 0.016771245150728965, 'n_estimators': 613, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.8881957448224139, 'colsample_bytree': 0.8908664255957943, 'gamma': 0.9711761215813887, 'lambda': 1.1386360158560018}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:54:56,425] Trial 85 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.9993785887706962, 'learning_rate': 0.03772330233100432, 'n_estimators': 670, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.85413251825965, 'colsample_bytree': 0.9291032958689469, 'gamma': 0.895111528672551, 'lambda': 0.8003599370004868}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:55:07,121] Trial 86 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.9755625406662178, 'learning_rate': 0.0385888229672814, 'n_estimators': 659, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8533164571846672, 'colsample_bytree': 0.936787566992947, 'gamma': 0.8519723911225092, 'lambda': 1.0740711086622206}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:55:14,313] Trial 87 finished with value: 0.8903780068728524 and parameters: {'booster': 'gbtree', 'eta': 0.9201681463483704, 'learning_rate': 0.0479856616946911, 'n_estimators': 629, 'max_depth': 1, 'min_child_weight': 6, 'subsample': 0.8741626620606204, 'colsample_bytree': 0.904841410263239, 'gamma': 0.897952070217165, 'lambda': 0.663238456819903}. Best is trial 60 with value: 0.9257731958762888.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:55:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:55:21,098] Trial 88 finished with value: 0.8109965635738834 and parameters: {'booster': 'gblinear', 'eta': 0.9532633627385577, 'learning_rate': 0.006902299339520565, 'n_estimators': 662, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.8362255127834861, 'colsample_bytree': 0.9570611010202645, 'gamma': 0.9466487990748501, 'lambda': 0.8320817798815294}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:55:39,449] Trial 89 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.8681249813482166, 'learning_rate': 0.026918172276128735, 'n_estimators': 605, 'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.8011351695735787, 'colsample_bytree': 0.9279699956759965, 'gamma': 0.8713919491500903, 'lambda': 0.9058731569070158}. Best is trial 60 with value: 0.9257731958762888.
[I 2024-06-06 10:55:50,576] Trial 90 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.9999856470537603, 'learning_rate': 0.06556187524125812, 'n_estimators': 744, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8991144525968159, 'colsample_bytree': 0.9465688649429564, 'gamma': 0.9103089919959941, 'lambda': 0.9938468976458521}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:56:01,684] Trial 91 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.9755650592073118, 'learning_rate': 0.06435734608723175, 'n_estimators': 735, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8985545092837987, 'colsample_bytree': 0.9481810635960358, 'gamma': 0.90835243184878, 'lambda': 0.989785288183627}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:56:12,901] Trial 92 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.9105555391792485, 'learning_rate': 0.05334646699307552, 'n_estimators': 741, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9157859604316575, 'colsample_bytree': 0.9775982573992527, 'gamma': 0.9163044818163764, 'lambda': 1.0100760824804715}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:56:22,909] Trial 93 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.9451252752469551, 'learning_rate': 0.06641877662767401, 'n_estimators': 735, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.8677005780913152, 'colsample_bytree': 0.9687387680348195, 'gamma': 0.9262013768623111, 'lambda': 1.016262570051425}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:56:34,549] Trial 94 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.9054607801124435, 'learning_rate': 0.05537505596311024, 'n_estimators': 705, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.8879890896174747, 'colsample_bytree': 0.9452592340204161, 'gamma': 0.8004724678459022, 'lambda': 1.213519514339045}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:56:44,770] Trial 95 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.9660713002403841, 'learning_rate': 0.07537388325951547, 'n_estimators': 745, 'max_depth': 2, 'min_child_weight': 6, 'subsample': 0.8562416322184966, 'colsample_bytree': 0.9952178132051429, 'gamma': 0.8297328993264369, 'lambda': 1.1080842340833785}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:56:54,278] Trial 96 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.8976870874020338, 'learning_rate': 0.07502985084343548, 'n_estimators': 677, 'max_depth': 2, 'min_child_weight': 6, 'subsample': 0.856048494043927, 'colsample_bytree': 0.9922982435238, 'gamma': 0.8297288610959437, 'lambda': 0.9664418260726004}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:57:02,271] Trial 97 finished with value: 0.9030927835051548 and parameters: {'booster': 'gbtree', 'eta': 0.8341578391492368, 'learning_rate': 0.06435184232052844, 'n_estimators': 701, 'max_depth': 1, 'min_child_weight': 5, 'subsample': 0.8209176026806198, 'colsample_bytree': 0.9815257705553557, 'gamma': 0.8651338364673927, 'lambda': 1.0926921604460396}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:57:11,296] Trial 98 finished with value: 0.905154639175258 and parameters: {'booster': 'gbtree', 'eta': 0.9648754586745326, 'learning_rate': 0.08158140959869817, 'n_estimators': 794, 'max_depth': 1, 'min_child_weight': 6, 'subsample': 0.8439925093275001, 'colsample_bytree': 0.9875338304642489, 'gamma': 0.7993947683817813, 'lambda': 1.1295243740339544}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:57:22,971] Trial 99 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.936313765447672, 'learning_rate': 0.052862904677482406, 'n_estimators': 752, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9172717417236627, 'colsample_bytree': 0.9979711335217956, 'gamma': 0.8510797244821487, 'lambda': 0.9949188050989543}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:57:36,195] Trial 100 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.9113808002693555, 'learning_rate': 0.05406237106211329, 'n_estimators': 736, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9117185016223368, 'colsample_bytree': 0.996871075934166, 'gamma': 0.8874427776963387, 'lambda': 1.0249055672707448}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:57:49,574] Trial 101 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.8658287013170486, 'learning_rate': 0.05385942699839563, 'n_estimators': 733, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9126497629361028, 'colsample_bytree': 0.9984433799127111, 'gamma': 0.8320386397323756, 'lambda': 1.0075463550509458}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:58:06,836] Trial 102 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.8680257202724017, 'learning_rate': 0.07066560150511658, 'n_estimators': 748, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.8831388937313439, 'colsample_bytree': 0.9758502374359267, 'gamma': 0.9148937181141168, 'lambda': 0.9544977953892256}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:58:17,504] Trial 103 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.9116916230412241, 'learning_rate': 0.05726202480326036, 'n_estimators': 741, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8696539037876189, 'colsample_bytree': 0.9988958520877407, 'gamma': 0.8279543301679377, 'lambda': 1.0407050005549137}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:58:29,662] Trial 104 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.8589516963296806, 'learning_rate': 0.048127980148353726, 'n_estimators': 686, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.9002189322085595, 'colsample_bytree': 0.984712463442726, 'gamma': 0.8882136005980191, 'lambda': 0.7301195847876059}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:58:42,479] Trial 105 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.8190888556435227, 'learning_rate': 0.06247330132417054, 'n_estimators': 726, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.913641545880892, 'colsample_bytree': 0.9882216822730459, 'gamma': 0.8889515068340119, 'lambda': 0.8840862378076914}. Best is trial 90 with value: 0.9261168384879727.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [10:58:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 10:58:49,649] Trial 106 finished with value: 0.8106529209621995 and parameters: {'booster': 'gblinear', 'eta': 0.8476273594160981, 'learning_rate': 0.04827856253639901, 'n_estimators': 686, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9039801060946434, 'colsample_bytree': 0.9592288128193883, 'gamma': 0.7883683275410878, 'lambda': 0.7247152411395457}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:59:01,819] Trial 107 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.8844836770545865, 'learning_rate': 0.06995394270441854, 'n_estimators': 788, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.8911555572527214, 'colsample_bytree': 0.9710313182835408, 'gamma': 0.9162672495744029, 'lambda': 1.0692219313029694}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 10:59:13,494] Trial 108 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.8000907157543179, 'learning_rate': 0.0799907765223814, 'n_estimators': 832, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.9407302139580156, 'colsample_bytree': 0.9818340589951307, 'gamma': 0.8734426000897096, 'lambda': 0.9098158947262819}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:00:01,795] Trial 109 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.8376196481967703, 'learning_rate': 0.07752905506422567, 'n_estimators': 836, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9300767444520559, 'colsample_bytree': 0.982792631472828, 'gamma': 0.8622415167666111, 'lambda': 0.9322885602908426}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:00:13,681] Trial 110 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7952719092926015, 'learning_rate': 0.08669986707468225, 'n_estimators': 755, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.9445097203330302, 'colsample_bytree': 0.9641406207198193, 'gamma': 0.9796437718364183, 'lambda': 1.167395963012096}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:00:26,493] Trial 111 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.8573958261236191, 'learning_rate': 0.05818166197583882, 'n_estimators': 716, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9160493039983526, 'colsample_bytree': 0.9773801730309165, 'gamma': 0.8824646224984481, 'lambda': 1.0139530937902017}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:00:39,055] Trial 112 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.8006605366111245, 'learning_rate': 0.045500996800212364, 'n_estimators': 781, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.8976714480584128, 'colsample_bytree': 0.998619390157071, 'gamma': 0.8339548520495844, 'lambda': 0.7598866066225483}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:00:50,117] Trial 113 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.7601352450953434, 'learning_rate': 0.09641324434813067, 'n_estimators': 791, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.8974320215112221, 'colsample_bytree': 0.9933577051780319, 'gamma': 0.8347030858001919, 'lambda': 0.8872183891037132}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:01:02,466] Trial 114 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.9108444160292191, 'learning_rate': 0.06527356017302287, 'n_estimators': 822, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9312067648945812, 'colsample_bytree': 0.965824330555787, 'gamma': 0.8237469459905207, 'lambda': 0.7712988476884608}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:01:15,826] Trial 115 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.8119816894078526, 'learning_rate': 0.04494331894118959, 'n_estimators': 861, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.908643290386166, 'colsample_bytree': 0.9879674360575478, 'gamma': 0.7778815140957667, 'lambda': 1.1227800935545247}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:01:29,692] Trial 116 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.7909660207378613, 'learning_rate': 0.052835445089239694, 'n_estimators': 763, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.8770016423853687, 'colsample_bytree': 0.9998041196161566, 'gamma': 0.8081062796445657, 'lambda': 0.9375050518836118}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:01:42,209] Trial 117 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.8237968406423584, 'learning_rate': 0.07520900635436276, 'n_estimators': 740, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.9530394279277119, 'colsample_bytree': 0.9461569120012469, 'gamma': 0.7649326194060952, 'lambda': 1.0360356361410479}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:01:53,661] Trial 118 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.7307093184925364, 'learning_rate': 0.060236939682161504, 'n_estimators': 785, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.9219874395500256, 'colsample_bytree': 0.982536879827951, 'gamma': 0.9231903981657347, 'lambda': 0.8619130654589844}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:02:06,296] Trial 119 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.8950875823865028, 'learning_rate': 0.08000115331311092, 'n_estimators': 818, 'max_depth': 16, 'min_child_weight': 5, 'subsample': 0.937930366432572, 'colsample_bytree': 0.9725204485657489, 'gamma': 0.9455736881296976, 'lambda': 1.0898299354995884}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:02:18,906] Trial 120 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.7644809339475822, 'learning_rate': 0.047479874442757454, 'n_estimators': 709, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.894944065701599, 'colsample_bytree': 0.9544328994732937, 'gamma': 0.8583178480166935, 'lambda': 0.7553212490321248}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:02:31,358] Trial 121 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.9163388691893285, 'learning_rate': 0.06542248746415479, 'n_estimators': 878, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.9281667738295243, 'colsample_bytree': 0.9685845004048583, 'gamma': 0.8226583307931354, 'lambda': 0.778200394903021}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:02:42,902] Trial 122 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.9398784572674886, 'learning_rate': 0.07098276767634974, 'n_estimators': 837, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.9325044002623032, 'colsample_bytree': 0.9637789523663297, 'gamma': 0.8771400357409247, 'lambda': 0.9780782853145596}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:02:53,895] Trial 123 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.940455660352129, 'learning_rate': 0.07090157348013273, 'n_estimators': 802, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.9115374354810638, 'colsample_bytree': 0.9800348043637032, 'gamma': 0.8811408725827864, 'lambda': 0.9904560379267627}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:03:04,194] Trial 124 finished with value: 0.9192439862542957 and parameters: {'booster': 'gbtree', 'eta': 0.9732580064214904, 'learning_rate': 0.053793966120713646, 'n_estimators': 730, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.9418684297077986, 'colsample_bytree': 0.9999579796160861, 'gamma': 0.8516784470680048, 'lambda': 0.8971037912500741}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:03:15,076] Trial 125 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.952457274033797, 'learning_rate': 0.0871883922043148, 'n_estimators': 835, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.960193563135852, 'colsample_bytree': 0.9469207928405514, 'gamma': 0.9805318560172492, 'lambda': 1.2390433998831294}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:03:29,699] Trial 126 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.803567895408085, 'learning_rate': 0.04616405663027449, 'n_estimators': 773, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8831520206153226, 'colsample_bytree': 0.9633325262964305, 'gamma': 0.9332389693620183, 'lambda': 0.9701722460187718}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:03:42,432] Trial 127 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.9280656534585042, 'learning_rate': 0.07695894997252581, 'n_estimators': 890, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.902173330909154, 'colsample_bytree': 0.9901300338844482, 'gamma': 0.8736446008799678, 'lambda': 1.0623968507916959}. Best is trial 90 with value: 0.9261168384879727.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:03:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:03:49,755] Trial 128 finished with value: 0.8075601374570449 and parameters: {'booster': 'gblinear', 'eta': 0.9753004034056036, 'learning_rate': 0.06783055328009041, 'n_estimators': 686, 'max_depth': 2, 'min_child_weight': 6, 'subsample': 0.9183521454329654, 'colsample_bytree': 0.9550361897941864, 'gamma': 0.912390427176895, 'lambda': 1.1615591369665528}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:04:00,305] Trial 129 finished with value: 0.9182130584192442 and parameters: {'booster': 'gbtree', 'eta': 0.8618700453615483, 'learning_rate': 0.061845337834572044, 'n_estimators': 814, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.9677923489972874, 'colsample_bytree': 0.9759477373998077, 'gamma': 0.9568884206828641, 'lambda': 0.6283317592591553}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:04:11,687] Trial 130 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.8857848892199839, 'learning_rate': 0.09811246310583481, 'n_estimators': 915, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.9311722104232883, 'colsample_bytree': 0.9844242770760446, 'gamma': 0.8916392157471177, 'lambda': 0.9279016359214116}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:04:24,526] Trial 131 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.9302516413847524, 'learning_rate': 0.05216410812757382, 'n_estimators': 765, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.9334188602958988, 'colsample_bytree': 0.9639894375237351, 'gamma': 0.8351647105168969, 'lambda': 0.8305906653606181}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:04:36,668] Trial 132 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.9042306267085355, 'learning_rate': 0.06590270756948512, 'n_estimators': 829, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.950636719309461, 'colsample_bytree': 0.9418287451536896, 'gamma': 0.8155583238998705, 'lambda': 0.7574415699001205}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:04:50,145] Trial 133 finished with value: 0.9192439862542957 and parameters: {'booster': 'gbtree', 'eta': 0.9535240101511372, 'learning_rate': 0.05856703663781771, 'n_estimators': 788, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.8948838399090159, 'colsample_bytree': 0.9662047542620356, 'gamma': 0.8026563546932555, 'lambda': 0.6853007102344504}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:05:01,705] Trial 134 finished with value: 0.9206185567010311 and parameters: {'booster': 'gbtree', 'eta': 0.8827107011042981, 'learning_rate': 0.07404879929767556, 'n_estimators': 852, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9203930481139141, 'colsample_bytree': 0.9764881540169156, 'gamma': 0.8407065730233053, 'lambda': 0.8497726646255941}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:05:13,301] Trial 135 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.9790814377849366, 'learning_rate': 0.08404253525042808, 'n_estimators': 808, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.9051382561937048, 'colsample_bytree': 0.9896026614157134, 'gamma': 0.8667770984276326, 'lambda': 1.0094093455247506}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:05:25,018] Trial 136 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.9131881797151803, 'learning_rate': 0.04367707847217672, 'n_estimators': 739, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9391289484100542, 'colsample_bytree': 0.955128385004153, 'gamma': 0.9413672674657032, 'lambda': 0.5544254889872999}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:05:34,030] Trial 137 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.6961364016236002, 'learning_rate': 0.11350321335402692, 'n_estimators': 699, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.8835495540188518, 'colsample_bytree': 0.9412671907182485, 'gamma': 0.7654774391925694, 'lambda': 1.10716141815181}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:05:47,984] Trial 138 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.8452845405221845, 'learning_rate': 0.05679057588258508, 'n_estimators': 756, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.9111258508172164, 'colsample_bytree': 0.9631349797002541, 'gamma': 0.901013140149814, 'lambda': 0.905708580811407}. Best is trial 90 with value: 0.9261168384879727.
[I 2024-06-06 11:06:05,501] Trial 139 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.827992930601394, 'learning_rate': 0.03125115439533929, 'n_estimators': 756, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.9139474766672531, 'colsample_bytree': 0.9910477932838767, 'gamma': 0.919464954594057, 'lambda': 0.9580882773620412}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:06:21,995] Trial 140 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.7901029092536281, 'learning_rate': 0.03384804618336675, 'n_estimators': 717, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.910868218616539, 'colsample_bytree': 0.9753272376778666, 'gamma': 0.9970127451558819, 'lambda': 0.9551697949263037}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:06:37,924] Trial 141 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7877975374322872, 'learning_rate': 0.03635379042289957, 'n_estimators': 720, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.9148778749509302, 'colsample_bytree': 0.9771411939441332, 'gamma': 0.9774220386286185, 'lambda': 0.9655092469391632}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:06:56,445] Trial 142 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.835821767620215, 'learning_rate': 0.030203950982160478, 'n_estimators': 770, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.9097529758799595, 'colsample_bytree': 0.9574578757510783, 'gamma': 0.9920603294172472, 'lambda': 0.9099323746884581}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:07:14,264] Trial 143 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.8139916533356537, 'learning_rate': 0.03217408558547512, 'n_estimators': 754, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8973098413189281, 'colsample_bytree': 0.9831448772894135, 'gamma': 0.914506021613612, 'lambda': 1.0206361983229406}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:07:35,595] Trial 144 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.8151589165449215, 'learning_rate': 0.021716859707487608, 'n_estimators': 706, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.893177862854207, 'colsample_bytree': 0.9858164797024541, 'gamma': 0.9558825419638907, 'lambda': 0.8621621963142883}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:07:52,771] Trial 145 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.769913577619685, 'learning_rate': 0.0346747897787608, 'n_estimators': 685, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.9019138387884648, 'colsample_bytree': 0.9487100766642402, 'gamma': 0.8984625652673863, 'lambda': 0.9469337123805743}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:08:10,036] Trial 146 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7703316061043345, 'learning_rate': 0.03330254186301681, 'n_estimators': 684, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.8754840367441056, 'colsample_bytree': 0.9343663342160082, 'gamma': 0.8976266976671683, 'lambda': 0.9505384789840002}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:08:26,753] Trial 147 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.7974418501597057, 'learning_rate': 0.04094559047288204, 'n_estimators': 776, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9008175701562896, 'colsample_bytree': 0.9451915142378228, 'gamma': 0.9284860877437469, 'lambda': 1.0397815576932152}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:08:42,322] Trial 148 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.8474404412491043, 'learning_rate': 0.04347379972511738, 'n_estimators': 760, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8881668947146976, 'colsample_bytree': 0.9992665156269958, 'gamma': 0.9364942006662588, 'lambda': 1.0332192696381646}. Best is trial 139 with value: 0.9268041237113404.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:08:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:08:50,274] Trial 149 finished with value: 0.8085910652920965 and parameters: {'booster': 'gblinear', 'eta': 0.8468814652779658, 'learning_rate': 0.04284697862240183, 'n_estimators': 761, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8874642927717762, 'colsample_bytree': 0.9955536921461035, 'gamma': 0.9202196239595618, 'lambda': 1.054352312398297}. Best is trial 139 with value: 0.9268041237113404.
[I 2024-06-06 11:09:05,873] Trial 150 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.8275486935471881, 'learning_rate': 0.047308387740283404, 'n_estimators': 790, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8733798505684464, 'colsample_bytree': 0.9989053023894311, 'gamma': 0.8800479456848989, 'lambda': 1.054907827949784}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:09:57,577] Trial 151 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.8188838336078326, 'learning_rate': 0.0441261822703386, 'n_estimators': 786, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8937789739124405, 'colsample_bytree': 0.9876023108708223, 'gamma': 0.876346107228893, 'lambda': 1.0068412989861957}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:10:13,302] Trial 152 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.8260781875119165, 'learning_rate': 0.047187199056353005, 'n_estimators': 795, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8709887662112457, 'colsample_bytree': 0.99998618222998, 'gamma': 0.8716369620074775, 'lambda': 1.0409440542605894}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:10:30,340] Trial 153 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.8211729392593512, 'learning_rate': 0.04041044189476627, 'n_estimators': 796, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8720296884627797, 'colsample_bytree': 0.9994191854187086, 'gamma': 0.8560903251170485, 'lambda': 1.0333790223700845}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:10:46,998] Trial 154 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.8182096926630373, 'learning_rate': 0.04204702051770331, 'n_estimators': 797, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8688786106179512, 'colsample_bytree': 0.9994669779851645, 'gamma': 0.8686354192080106, 'lambda': 1.0470688159995896}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:11:02,830] Trial 155 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.8048728219683902, 'learning_rate': 0.049617492866340096, 'n_estimators': 851, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8837743415088273, 'colsample_bytree': 0.989733555509696, 'gamma': 0.8621714420676315, 'lambda': 1.1814053288918789}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:11:19,601] Trial 156 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.8281108317087438, 'learning_rate': 0.04021571181035678, 'n_estimators': 776, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.868678116739286, 'colsample_bytree': 0.9907319084769008, 'gamma': 0.8795589242080559, 'lambda': 1.1465419628040514}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:11:40,264] Trial 157 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.8021194193412484, 'learning_rate': 0.027255531311532126, 'n_estimators': 804, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8940152736169409, 'colsample_bytree': 0.997893206350456, 'gamma': 0.849501113721104, 'lambda': 1.0846036199178777}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:11:54,953] Trial 158 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.748756969012076, 'learning_rate': 0.050470324802861045, 'n_estimators': 786, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.8821409655935878, 'colsample_bytree': 0.9825141673543958, 'gamma': 0.9272615854549744, 'lambda': 1.0203717586925924}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:13:58,822] Trial 159 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7865996979244056, 'learning_rate': 0.05865347215369858, 'n_estimators': 828, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.875479372033872, 'colsample_bytree': 0.9688142863930347, 'gamma': 0.8797193700936542, 'lambda': 1.0136080065082087}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:14:13,276] Trial 160 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7900911111737158, 'learning_rate': 0.056614439572407305, 'n_estimators': 824, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8620259740893325, 'colsample_bytree': 0.9694720661163873, 'gamma': 0.9126488823428685, 'lambda': 1.1024669781345502}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:14:30,018] Trial 161 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.8331577219249415, 'learning_rate': 0.04411455992469031, 'n_estimators': 871, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8780530088729783, 'colsample_bytree': 0.9895388044603273, 'gamma': 0.8811323516637845, 'lambda': 1.008166876359599}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:14:44,409] Trial 162 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.7491677021975213, 'learning_rate': 0.061264309551570174, 'n_estimators': 841, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8935275947478989, 'colsample_bytree': 0.9752155097045501, 'gamma': 0.8461046332396376, 'lambda': 1.050414675781418}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:14:59,260] Trial 163 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.7811249299829077, 'learning_rate': 0.05070608646088723, 'n_estimators': 800, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9252705962318901, 'colsample_bytree': 0.9979974079861387, 'gamma': 0.9367136100197333, 'lambda': 1.0075351937316301}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:15:13,665] Trial 164 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.7755047836148229, 'learning_rate': 0.05085016890023784, 'n_estimators': 755, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9214195902421418, 'colsample_bytree': 0.9845477665771224, 'gamma': 0.9313565078546998, 'lambda': 1.0006264217553844}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:15:27,955] Trial 165 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.730149572687201, 'learning_rate': 0.057286218094275816, 'n_estimators': 773, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9028892231575486, 'colsample_bytree': 0.9668645445513088, 'gamma': 0.940534762283671, 'lambda': 1.141632136860745}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:15:42,002] Trial 166 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.7627394326298037, 'learning_rate': 0.054824223436849166, 'n_estimators': 775, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9036923223912753, 'colsample_bytree': 0.9741509400708683, 'gamma': 0.9465037755734582, 'lambda': 1.1854114966313671}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:15:56,482] Trial 167 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.7142829510598696, 'learning_rate': 0.055428215450269484, 'n_estimators': 775, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.9015477813905821, 'colsample_bytree': 0.9727324674613022, 'gamma': 0.9489874297365645, 'lambda': 1.2087600256080213}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:16:12,195] Trial 168 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.7517181791919785, 'learning_rate': 0.048153000280495864, 'n_estimators': 778, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.9007728634408076, 'colsample_bytree': 0.9556189653572736, 'gamma': 0.9465841272393785, 'lambda': 1.273178818670165}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:16:27,886] Trial 169 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7244002663776595, 'learning_rate': 0.045572571542054886, 'n_estimators': 768, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8991000402329582, 'colsample_bytree': 0.9572335929767869, 'gamma': 0.9540131143065703, 'lambda': 1.2472444791523207}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:16:43,576] Trial 170 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.7197926148371512, 'learning_rate': 0.04439766166080037, 'n_estimators': 767, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8893615901777485, 'colsample_bytree': 0.9498297116937282, 'gamma': 0.9593773429555728, 'lambda': 1.2823743447572475}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:16:59,033] Trial 171 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.7016811018248701, 'learning_rate': 0.045777393255254, 'n_estimators': 775, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8989787683077177, 'colsample_bytree': 0.9481673148945274, 'gamma': 0.9625422726405277, 'lambda': 1.2732504929198307}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:17:14,812] Trial 172 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7207299313584818, 'learning_rate': 0.044538488542597815, 'n_estimators': 778, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8899915295664537, 'colsample_bytree': 0.95110366770968, 'gamma': 0.9586660269427326, 'lambda': 1.2376796301907742}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:17:31,480] Trial 173 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7304646289434722, 'learning_rate': 0.037942397803803554, 'n_estimators': 764, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.9030208833034101, 'colsample_bytree': 0.9377036707616025, 'gamma': 0.9713577173865348, 'lambda': 1.2874293143139635}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:17:50,169] Trial 174 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7160125692219935, 'learning_rate': 0.030615196275119026, 'n_estimators': 775, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.9018701483728422, 'colsample_bytree': 0.9394779000806498, 'gamma': 0.9593109476907056, 'lambda': 1.3085882891188572}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:18:07,279] Trial 175 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7319444074207117, 'learning_rate': 0.03737775597006062, 'n_estimators': 756, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8787857593514237, 'colsample_bytree': 0.958451890754356, 'gamma': 0.9481244577887531, 'lambda': 1.3312867744403643}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:18:22,962] Trial 176 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.6961219024332479, 'learning_rate': 0.04530981935281817, 'n_estimators': 813, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8885121183690904, 'colsample_bytree': 0.9330557299224128, 'gamma': 0.9719156113890773, 'lambda': 1.2636876348928479}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:18:44,410] Trial 177 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.6710773200214467, 'learning_rate': 0.02283374012192541, 'n_estimators': 782, 'max_depth': 14, 'min_child_weight': 5, 'subsample': 0.8993025026202237, 'colsample_bytree': 0.9695278032422329, 'gamma': 0.9685627398553561, 'lambda': 1.2775024877546544}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:19:01,623] Trial 178 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.7491748889825056, 'learning_rate': 0.03847234076536502, 'n_estimators': 752, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8489901785196265, 'colsample_bytree': 0.9559838289959098, 'gamma': 0.9475602735481429, 'lambda': 1.3508360537498574}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:20:54,702] Trial 179 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7628092908926036, 'learning_rate': 0.030649214388513642, 'n_estimators': 751, 'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.8527233162296406, 'colsample_bytree': 0.9615109034977699, 'gamma': 0.9453132838049109, 'lambda': 1.198290736258957}. Best is trial 150 with value: 0.9281786941580757.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:56] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:56] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:58] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:20:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:21:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:21:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:21:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:21:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:21:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:21:03,117] Trial 180 finished with value: 0.8068728522336772 and parameters: {'booster': 'gblinear', 'eta': 0.706494309195795, 'learning_rate': 0.04696490435297293, 'n_estimators': 805, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8642304753926819, 'colsample_bytree': 0.9473867789100286, 'gamma': 0.9336219818713105, 'lambda': 1.3494738778118658}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:21:19,767] Trial 181 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7221124750105146, 'learning_rate': 0.03793492990423729, 'n_estimators': 767, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8838141007832098, 'colsample_bytree': 0.9246451332955868, 'gamma': 0.9792563654823053, 'lambda': 1.230231437856245}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:21:45,846] Trial 182 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7465228210865011, 'learning_rate': 0.017154058432669338, 'n_estimators': 782, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8969420496351015, 'colsample_bytree': 0.9699619816384183, 'gamma': 0.9211274196317724, 'lambda': 1.375854938868918}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:22:06,232] Trial 183 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.732031545845935, 'learning_rate': 0.027200849407140397, 'n_estimators': 730, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8701291739032141, 'colsample_bytree': 0.9541678432780583, 'gamma': 0.9501655915834937, 'lambda': 1.2718666099102869}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:22:22,712] Trial 184 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.6742975957338334, 'learning_rate': 0.03964565791232758, 'n_estimators': 751, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8781612991044334, 'colsample_bytree': 0.9394313473385604, 'gamma': 0.9763552095451871, 'lambda': 1.1950961440364702}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:22:40,316] Trial 185 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7471778505306409, 'learning_rate': 0.034340815942985325, 'n_estimators': 769, 'max_depth': 14, 'min_child_weight': 5, 'subsample': 0.8442735583943861, 'colsample_bytree': 0.9728664301451712, 'gamma': 0.9424538722182142, 'lambda': 1.144777114900815}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:22:56,220] Trial 186 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.758426851047116, 'learning_rate': 0.045933759923920646, 'n_estimators': 813, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9050703073566655, 'colsample_bytree': 0.9194910542243196, 'gamma': 0.9170419990372481, 'lambda': 1.3103338752455476}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:23:11,289] Trial 187 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.7668918220904676, 'learning_rate': 0.05778139524584403, 'n_estimators': 812, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8301179975977896, 'colsample_bytree': 0.958841849123717, 'gamma': 0.9132755591662141, 'lambda': 1.1956469009932338}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:23:27,118] Trial 188 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.6417338649499432, 'learning_rate': 0.04733771425047018, 'n_estimators': 854, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.8903555797726439, 'colsample_bytree': 0.9793481343999135, 'gamma': 0.9274551625859706, 'lambda': 1.4091677694044396}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:23:37,642] Trial 189 finished with value: 0.9168384879725088 and parameters: {'booster': 'gbtree', 'eta': 0.7542726412536845, 'learning_rate': 0.15952816462588726, 'n_estimators': 788, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9052819076397277, 'colsample_bytree': 0.9174397857877791, 'gamma': 0.9036379028220822, 'lambda': 1.230239508169495}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:23:53,103] Trial 190 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7067571848456266, 'learning_rate': 0.05252961972652447, 'n_estimators': 821, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8588091877148407, 'colsample_bytree': 0.9491011501529928, 'gamma': 0.9546681193501775, 'lambda': 1.3299889216004255}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:24:09,063] Trial 191 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.7403312766875934, 'learning_rate': 0.04084585524431769, 'n_estimators': 751, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.9040183125431646, 'colsample_bytree': 0.9328254582034108, 'gamma': 0.9669021933507781, 'lambda': 1.2969148609293721}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:24:26,548] Trial 192 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.6905928901090987, 'learning_rate': 0.04458158525541322, 'n_estimators': 729, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8932810900228212, 'colsample_bytree': 0.9423552981476714, 'gamma': 0.5419167301502287, 'lambda': 1.2787242635250478}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:24:43,853] Trial 193 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.6914141777425621, 'learning_rate': 0.04503534959567999, 'n_estimators': 726, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8849333410465465, 'colsample_bytree': 0.9613315606281, 'gamma': 0.5843146264168841, 'lambda': 1.1476202447948436}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:24:58,765] Trial 194 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.6886179425950427, 'learning_rate': 0.05548850449160227, 'n_estimators': 710, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8836945976176462, 'colsample_bytree': 0.9701485433910398, 'gamma': 0.5521496709258581, 'lambda': 1.1398987858119976}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:25:15,444] Trial 195 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.6861683256604245, 'learning_rate': 0.04961672254042604, 'n_estimators': 730, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8878662777801888, 'colsample_bytree': 0.9461138644902388, 'gamma': 0.5510443183315334, 'lambda': 1.1093572599817383}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:25:35,633] Trial 196 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.662266995057173, 'learning_rate': 0.03185092743808063, 'n_estimators': 716, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8881870050114946, 'colsample_bytree': 0.9856212665199566, 'gamma': 0.5103684207068275, 'lambda': 1.1635603430362782}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:25:52,637] Trial 197 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7041105099451394, 'learning_rate': 0.04355054782950374, 'n_estimators': 729, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.7787159826966775, 'colsample_bytree': 0.9743598602064382, 'gamma': 0.5769635050767485, 'lambda': 1.1489116826504642}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:26:08,053] Trial 198 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.6833001966161705, 'learning_rate': 0.054791511615892394, 'n_estimators': 701, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.876223283988345, 'colsample_bytree': 0.9631963669620497, 'gamma': 0.6010158664987404, 'lambda': 1.3773086196069126}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:26:29,953] Trial 199 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.6319707450638219, 'learning_rate': 0.023063002259032957, 'n_estimators': 715, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9087159833743076, 'colsample_bytree': 0.7190126057872037, 'gamma': 0.6897193341901422, 'lambda': 1.194220471854749}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:26:53,090] Trial 200 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.6898331161782595, 'learning_rate': 0.021584213030001922, 'n_estimators': 714, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9127855215507956, 'colsample_bytree': 0.7021763158913094, 'gamma': 0.6071073360805043, 'lambda': 1.2277441602761465}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:27:15,385] Trial 201 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.6549632621501884, 'learning_rate': 0.026162615938659144, 'n_estimators': 741, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8930070380327847, 'colsample_bytree': 0.9826770018029939, 'gamma': 0.5455038585780746, 'lambda': 1.1115622812771278}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:27:32,690] Trial 202 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.6157273666182717, 'learning_rate': 0.03538576123319367, 'n_estimators': 744, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9104908997545235, 'colsample_bytree': 0.9539358079803606, 'gamma': 0.9272238707459083, 'lambda': 1.1985920635940248}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:28:05,774] Trial 203 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.7098728669063948, 'learning_rate': 0.011638520481569067, 'n_estimators': 780, 'max_depth': 14, 'min_child_weight': 5, 'subsample': 0.8835400409168763, 'colsample_bytree': 0.967498053200542, 'gamma': 0.9081413516092378, 'lambda': 1.3030596452605445}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:28:22,352] Trial 204 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.7664775470111618, 'learning_rate': 0.0443357279194013, 'n_estimators': 795, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8957295686047786, 'colsample_bytree': 0.9271278762954042, 'gamma': 0.7072166274062552, 'lambda': 1.1604118706266575}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:28:33,629] Trial 205 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.7596551733139395, 'learning_rate': 0.13786483369900393, 'n_estimators': 797, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8994750425603226, 'colsample_bytree': 0.9327018223970187, 'gamma': 0.6802759993773284, 'lambda': 1.1765825843350637}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:28:49,153] Trial 206 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7389602186545985, 'learning_rate': 0.047837023955328836, 'n_estimators': 724, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.9198926022992324, 'colsample_bytree': 0.9182729738473702, 'gamma': 0.6536522407305512, 'lambda': 1.2618442511612298}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:29:05,000] Trial 207 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.6807098445854738, 'learning_rate': 0.053852176794337396, 'n_estimators': 790, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9062867755896776, 'colsample_bytree': 0.9460556208988911, 'gamma': 0.636405140553399, 'lambda': 1.1332366913732055}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:29:20,181] Trial 208 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.6783558240311944, 'learning_rate': 0.06209114788854993, 'n_estimators': 803, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.863426365421383, 'colsample_bytree': 0.926521321298018, 'gamma': 0.6028006394875152, 'lambda': 1.1210375174782345}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:29:34,481] Trial 209 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.702704924856813, 'learning_rate': 0.055278821472111536, 'n_estimators': 702, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9041649625404823, 'colsample_bytree': 0.943252135063051, 'gamma': 0.7148543102668221, 'lambda': 1.0884736518754246}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:29:51,826] Trial 210 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.6387228069725033, 'learning_rate': 0.03905803180576777, 'n_estimators': 743, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9182636272891627, 'colsample_bytree': 0.7823462729841166, 'gamma': 0.618882429369838, 'lambda': 1.3295505324391874}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:30:07,629] Trial 211 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.7173454319247135, 'learning_rate': 0.05058753431306573, 'n_estimators': 785, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8959006033865545, 'colsample_bytree': 0.7512132742387843, 'gamma': 0.5809610230531279, 'lambda': 1.1638072808868467}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:30:22,869] Trial 212 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.692837920023403, 'learning_rate': 0.04952586419410873, 'n_estimators': 763, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9078944157479388, 'colsample_bytree': 0.6885011244904331, 'gamma': 0.6317487826328646, 'lambda': 1.186498256080266}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:30:38,030] Trial 213 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.7194395584289648, 'learning_rate': 0.05327243451205067, 'n_estimators': 803, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.894071485972751, 'colsample_bytree': 0.5811854092801343, 'gamma': 0.6536024883302896, 'lambda': 1.143386235433032}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:30:53,392] Trial 214 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.6614878699624401, 'learning_rate': 0.06249046833000484, 'n_estimators': 783, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.7126025298294981, 'colsample_bytree': 0.7525926273805758, 'gamma': 0.5686477149695905, 'lambda': 1.2441582596180913}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:31:10,946] Trial 215 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.7755341300350511, 'learning_rate': 0.035698414332656386, 'n_estimators': 750, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8772399601028882, 'colsample_bytree': 0.7571208225462281, 'gamma': 0.7321524139814038, 'lambda': 1.1577207164414005}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:31:30,304] Trial 216 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.7742705555113271, 'learning_rate': 0.030807180452087062, 'n_estimators': 789, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8756287666095942, 'colsample_bytree': 0.7514051972937342, 'gamma': 0.744910081626239, 'lambda': 1.194200071248212}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:31:55,250] Trial 217 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7413875016097264, 'learning_rate': 0.019883178712137538, 'n_estimators': 830, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8823864127186701, 'colsample_bytree': 0.7148701762086958, 'gamma': 0.7172842672906945, 'lambda': 1.1572355602168736}. Best is trial 150 with value: 0.9281786941580757.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:56] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:57] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:58] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:31:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:32:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:32:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:32:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:32:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:32:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:32:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:32:03,057] Trial 218 finished with value: 0.8085910652920965 and parameters: {'booster': 'gblinear', 'eta': 0.7192747601913757, 'learning_rate': 0.03648266396307982, 'n_estimators': 757, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8712132002349292, 'colsample_bytree': 0.7455546251022809, 'gamma': 0.6998795343826633, 'lambda': 1.085066120094538}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:32:18,769] Trial 219 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.7574570774392094, 'learning_rate': 0.04093232278900874, 'n_estimators': 722, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.8917232123913525, 'colsample_bytree': 0.7282761499298471, 'gamma': 0.7371061694746143, 'lambda': 1.270643816262705}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:32:40,676] Trial 220 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.6843681064748671, 'learning_rate': 0.02804962530847491, 'n_estimators': 867, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9110564702984333, 'colsample_bytree': 0.8076130442897967, 'gamma': 0.6714377644477975, 'lambda': 1.3591519717374005}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:33:00,530] Trial 221 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.7746649809512017, 'learning_rate': 0.19317980872195167, 'n_estimators': 742, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8998224964088969, 'colsample_bytree': 0.7930168799109274, 'gamma': 0.6405363771419789, 'lambda': 1.0813229749798077}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:33:16,040] Trial 222 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.7373958395914942, 'learning_rate': 0.04949828413333087, 'n_estimators': 769, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8834510494851775, 'colsample_bytree': 0.6681235569388111, 'gamma': 0.5853846081202864, 'lambda': 1.452565379280711}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:33:33,233] Trial 223 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.707721281210908, 'learning_rate': 0.04381540406477874, 'n_estimators': 789, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8474286537595956, 'colsample_bytree': 0.7579448790027363, 'gamma': 0.5437364248628503, 'lambda': 1.1350439804915249}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:33:51,278] Trial 224 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7067105229548618, 'learning_rate': 0.04197584553109618, 'n_estimators': 816, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8541700634534246, 'colsample_bytree': 0.8325136784566198, 'gamma': 0.5434666347304838, 'lambda': 1.139210605019063}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:34:10,701] Trial 225 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7198100117142864, 'learning_rate': 0.03392305516303197, 'n_estimators': 791, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8659508522318475, 'colsample_bytree': 0.7618449648277351, 'gamma': 0.5291561061021657, 'lambda': 1.2262559654684608}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:36:39,228] Trial 226 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.6764099438531285, 'learning_rate': 0.046158143862795896, 'n_estimators': 1012, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9224250882933384, 'colsample_bytree': 0.7689642811271536, 'gamma': 0.5784046357255197, 'lambda': 1.2025316452890038}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:36:54,733] Trial 227 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7531955142853779, 'learning_rate': 0.05637705687666211, 'n_estimators': 771, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8535116668589846, 'colsample_bytree': 0.7601325475631466, 'gamma': 0.5676423720469926, 'lambda': 1.1224204038584897}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:37:26,360] Trial 228 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7952705634439121, 'learning_rate': 0.01612246012544064, 'n_estimators': 979, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8380036379879381, 'colsample_bytree': 0.7469029311398133, 'gamma': 0.6795693783670989, 'lambda': 1.289605520491219}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:37:44,531] Trial 229 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.702951647118095, 'learning_rate': 0.042096865363578456, 'n_estimators': 804, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8302924559736584, 'colsample_bytree': 0.7364801400837917, 'gamma': 0.5498852599817363, 'lambda': 1.1634182362122631}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:38:04,159] Trial 230 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.7320749380116512, 'learning_rate': 0.03542724006001455, 'n_estimators': 757, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8459790307496603, 'colsample_bytree': 0.7840746139984066, 'gamma': 0.5216064379940784, 'lambda': 1.0844950715491641}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:38:23,513] Trial 231 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7314882788843631, 'learning_rate': 0.03544202505257554, 'n_estimators': 751, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8491990168612092, 'colsample_bytree': 0.7679534209160587, 'gamma': 0.5144266990161647, 'lambda': 1.0737757512410848}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:38:58,992] Trial 232 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7760437335717341, 'learning_rate': 0.025309748254736572, 'n_estimators': 778, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8922770696609245, 'colsample_bytree': 0.7402722582944847, 'gamma': 0.4811764809533124, 'lambda': 1.84152095551767}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:39:15,120] Trial 233 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.556738391791579, 'learning_rate': 0.05052458045023919, 'n_estimators': 733, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8429030376953929, 'colsample_bytree': 0.758626949016858, 'gamma': 0.5136909405704105, 'lambda': 1.2284948611429327}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:39:59,661] Trial 234 finished with value: 0.9037800687285226 and parameters: {'booster': 'gbtree', 'eta': 0.6898117310874152, 'learning_rate': 0.003844189663296159, 'n_estimators': 758, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8729649457160082, 'colsample_bytree': 0.8325873036911762, 'gamma': 0.6209874556486663, 'lambda': 1.0787712651363073}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:40:18,035] Trial 235 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.7477809684248757, 'learning_rate': 0.040359039668874046, 'n_estimators': 789, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.9079321888661553, 'colsample_bytree': 0.8972991538296522, 'gamma': 0.5913153628541179, 'lambda': 1.1230198488754253}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:40:39,284] Trial 236 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.8077738123151158, 'learning_rate': 0.0314181969598967, 'n_estimators': 840, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8822239084415535, 'colsample_bytree': 0.7366170968642128, 'gamma': 0.5332907479582528, 'lambda': 1.1646187969176305}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:40:56,113] Trial 237 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7160758191234554, 'learning_rate': 0.04575901095294679, 'n_estimators': 712, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8259734979017981, 'colsample_bytree': 0.8595185065324664, 'gamma': 0.5565466599496032, 'lambda': 1.3126812750223007}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:41:16,151] Trial 238 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.6578059115967112, 'learning_rate': 0.036806842513102817, 'n_estimators': 817, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8610600259240999, 'colsample_bytree': 0.7871512438929261, 'gamma': 0.4936298834854701, 'lambda': 1.2542556407801662}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:41:33,147] Trial 239 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.7655812883500324, 'learning_rate': 0.055798338413540566, 'n_estimators': 903, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.8952205438221975, 'colsample_bytree': 0.7785508999328727, 'gamma': 0.5273690394900209, 'lambda': 1.6027194184700002}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:41:44,761] Trial 240 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.724676535887602, 'learning_rate': 0.12009931051540601, 'n_estimators': 762, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9076739922881263, 'colsample_bytree': 0.8728362676839577, 'gamma': 0.5580822185271562, 'lambda': 1.1994629928993759}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:41:56,632] Trial 241 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7026614907196469, 'learning_rate': 0.10844231673192896, 'n_estimators': 767, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9064893095312536, 'colsample_bytree': 0.7725513022570141, 'gamma': 0.5634926437939509, 'lambda': 1.1713506146666406}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:42:08,338] Trial 242 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.7369377165292256, 'learning_rate': 0.11555731715474434, 'n_estimators': 740, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9015362829437753, 'colsample_bytree': 0.938299109148857, 'gamma': 0.5815915864087055, 'lambda': 1.2072410885126366}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:42:19,644] Trial 243 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.7315764230240523, 'learning_rate': 0.12206841712505967, 'n_estimators': 727, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9160192874278608, 'colsample_bytree': 0.9416862202749823, 'gamma': 0.5909645359052879, 'lambda': 1.2204085567357132}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:42:31,259] Trial 244 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.7316474625504865, 'learning_rate': 0.11525420792408933, 'n_estimators': 705, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.812267951581055, 'colsample_bytree': 0.9162827850381329, 'gamma': 0.576889984903927, 'lambda': 1.2178237799705078}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:42:42,580] Trial 245 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.7455100172074334, 'learning_rate': 0.11675905514858505, 'n_estimators': 687, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8334556204859764, 'colsample_bytree': 0.912797671181998, 'gamma': 0.5716784761068853, 'lambda': 1.2618664929707588}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:42:54,345] Trial 246 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.7281506551327366, 'learning_rate': 0.11323076469247517, 'n_estimators': 706, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8175183236546261, 'colsample_bytree': 0.9218528199268564, 'gamma': 0.5470407771756237, 'lambda': 1.2200775629116536}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:43:06,202] Trial 247 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7237136672045662, 'learning_rate': 0.12008297423228421, 'n_estimators': 733, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8417624509398048, 'colsample_bytree': 0.9312709951182636, 'gamma': 0.5257984774314376, 'lambda': 1.32399307624467}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:43:18,197] Trial 248 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.737385037299733, 'learning_rate': 0.1059486260579283, 'n_estimators': 756, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9174653256128061, 'colsample_bytree': 0.9025112068667329, 'gamma': 0.5955649879672061, 'lambda': 1.210697231350601}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:43:29,475] Trial 249 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7601715093056558, 'learning_rate': 0.12354437341309114, 'n_estimators': 712, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9003999073732846, 'colsample_bytree': 0.9361967769909013, 'gamma': 0.5644178958331555, 'lambda': 1.2825531186259973}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:43:51,483] Trial 250 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7153425763885396, 'learning_rate': 0.1356614387720843, 'n_estimators': 1839, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.924975575234632, 'colsample_bytree': 0.805896615362366, 'gamma': 0.6088318797853534, 'lambda': 2.144147813103452}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:44:07,452] Trial 251 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.7437621930312446, 'learning_rate': 0.10435797072414371, 'n_estimators': 1079, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8073491976682521, 'colsample_bytree': 0.9180979641562738, 'gamma': 0.5919540090097929, 'lambda': 1.3643019312446292}. Best is trial 150 with value: 0.9281786941580757.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:44:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:44:15,481] Trial 252 finished with value: 0.8075601374570449 and parameters: {'booster': 'gblinear', 'eta': 0.7911405372032798, 'learning_rate': 0.12628625552805783, 'n_estimators': 773, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.820672587496738, 'colsample_bytree': 0.8717801740416923, 'gamma': 0.5482682074322662, 'lambda': 1.247002585047561}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:44:32,910] Trial 253 finished with value: 0.9164948453608248 and parameters: {'booster': 'gbtree', 'eta': 0.8205544849079265, 'learning_rate': 0.12176172825774151, 'n_estimators': 1126, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.5128950418928541, 'colsample_bytree': 0.8414551792494717, 'gamma': 0.5001640631470604, 'lambda': 1.4030260419548508}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:44:44,501] Trial 254 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.761611863847504, 'learning_rate': 0.13365476068568474, 'n_estimators': 742, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9142175339948472, 'colsample_bytree': 0.9401048535637113, 'gamma': 0.4673794630010645, 'lambda': 1.0615726073914018}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:44:55,558] Trial 255 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7281815022745228, 'learning_rate': 0.11722485247320842, 'n_estimators': 727, 'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.8098264492856828, 'colsample_bytree': 0.8207099784018395, 'gamma': 0.7745282348136097, 'lambda': 1.297187099653062}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:45:07,882] Trial 256 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.7101604675768972, 'learning_rate': 0.12343302985634072, 'n_estimators': 801, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8464077685371623, 'colsample_bytree': 0.880687561994092, 'gamma': 0.5746671316895171, 'lambda': 1.2015926361019884}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:45:18,258] Trial 257 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.4261178852504103, 'learning_rate': 0.14550156944335105, 'n_estimators': 672, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8967992140817568, 'colsample_bytree': 0.9244046893782266, 'gamma': 0.5301370553886923, 'lambda': 1.3360437994473393}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:45:34,820] Trial 258 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.7871361862464333, 'learning_rate': 0.04985972019702967, 'n_estimators': 776, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9100594900554178, 'colsample_bytree': 0.911057861996074, 'gamma': 0.6169288543769077, 'lambda': 1.0914609722463722}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:45:45,971] Trial 259 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.8145326421211903, 'learning_rate': 0.12896827797705712, 'n_estimators': 696, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.7865143806641344, 'colsample_bytree': 0.84755818718183, 'gamma': 0.5867529367525897, 'lambda': 1.0726979489767148}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:45:58,117] Trial 260 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7976942476965707, 'learning_rate': 0.11398852856312304, 'n_estimators': 772, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8917377673062489, 'colsample_bytree': 0.9092223215193306, 'gamma': 0.5620685438064879, 'lambda': 1.112000066880416}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:46:11,817] Trial 261 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.7816415320000026, 'learning_rate': 0.10047025513799027, 'n_estimators': 743, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.5727686029068169, 'colsample_bytree': 0.9521166132730777, 'gamma': 0.607221227649041, 'lambda': 1.0498380442649846}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:46:26,305] Trial 262 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.7363819168832916, 'learning_rate': 0.060184990741815755, 'n_estimators': 763, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9184339175991649, 'colsample_bytree': 0.8914331467973249, 'gamma': 0.6916221857056575, 'lambda': 1.1964822290251407}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:46:40,268] Trial 263 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.8314669131005409, 'learning_rate': 0.13144298124315779, 'n_estimators': 784, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.9098707356318053, 'colsample_bytree': 0.9405656757170008, 'gamma': 0.6146124216869837, 'lambda': 1.0933878660321656}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:46:53,843] Trial 264 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.6967548044152785, 'learning_rate': 0.1148003282849618, 'n_estimators': 936, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9290318825931501, 'colsample_bytree': 0.9554250403277562, 'gamma': 0.6576906303685439, 'lambda': 1.1869628700743682}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:47:05,425] Trial 265 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7491449368387071, 'learning_rate': 0.11041914016428447, 'n_estimators': 716, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8631596854156084, 'colsample_bytree': 0.9274617688491472, 'gamma': 0.6327256538411515, 'lambda': 1.248598521846001}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:47:17,047] Trial 266 finished with value: 0.9233676975945019 and parameters: {'booster': 'gbtree', 'eta': 0.7125419653159571, 'learning_rate': 0.10608147259457237, 'n_estimators': 748, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8894802684060829, 'colsample_bytree': 0.9738338717063446, 'gamma': 0.7170557140308278, 'lambda': 1.1354495668067495}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:47:31,254] Trial 267 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.7795177805684192, 'learning_rate': 0.05041686627331357, 'n_estimators': 730, 'max_depth': 14, 'min_child_weight': 5, 'subsample': 0.9008051459764869, 'colsample_bytree': 0.9027717634762634, 'gamma': 0.9961191783895251, 'lambda': 1.0455381345483639}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:47:42,017] Trial 268 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.18654498763065108, 'learning_rate': 0.16708465933907563, 'n_estimators': 788, 'max_depth': 15, 'min_child_weight': 6, 'subsample': 0.7686777213906195, 'colsample_bytree': 0.7303690313891545, 'gamma': 0.7576093828202217, 'lambda': 1.1221226061654375}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:47:59,420] Trial 269 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.6376789383303617, 'learning_rate': 0.12623143768387282, 'n_estimators': 1376, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8710916133301339, 'colsample_bytree': 0.960443176182417, 'gamma': 0.9420310463645667, 'lambda': 1.2091842514843312}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:48:12,842] Trial 270 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.807586120805665, 'learning_rate': 0.08973997479221521, 'n_estimators': 761, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8363161881393147, 'colsample_bytree': 0.9480030680584247, 'gamma': 0.5846845129513529, 'lambda': 1.4627759018349265}. Best is trial 150 with value: 0.9281786941580757.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:48:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:48:26,501] Trial 271 finished with value: 0.8075601374570449 and parameters: {'booster': 'gblinear', 'eta': 0.8260643704991584, 'learning_rate': 0.10362180900799589, 'n_estimators': 1321, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8457748380865918, 'colsample_bytree': 0.9324223003221231, 'gamma': 0.5836554784992047, 'lambda': 1.167484512679689}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:48:38,641] Trial 272 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.810808190498416, 'learning_rate': 0.08806586561835576, 'n_estimators': 640, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.83758543895541, 'colsample_bytree': 0.9866273358770854, 'gamma': 0.5530144914617554, 'lambda': 1.3987353615137859}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:48:50,228] Trial 273 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.7901231650195351, 'learning_rate': 0.1196405785914633, 'n_estimators': 755, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.8259307260449356, 'colsample_bytree': 0.8022971273776419, 'gamma': 0.6151982422443395, 'lambda': 1.0870368374250086}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:49:02,169] Trial 274 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.8501493120688935, 'learning_rate': 0.10276187283608719, 'n_estimators': 716, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8016764034722157, 'colsample_bytree': 0.7224749179078016, 'gamma': 0.5704123632204592, 'lambda': 1.4710917727423953}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:49:13,685] Trial 275 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.7666715524947816, 'learning_rate': 0.09742814497125568, 'n_estimators': 695, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8532039821233706, 'colsample_bytree': 0.7430781847518332, 'gamma': 0.6593201557158361, 'lambda': 1.427908030354127}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:52:20,986] Trial 276 finished with value: 0.9223367697594503 and parameters: {'booster': 'gbtree', 'eta': 0.8033767761456924, 'learning_rate': 0.11070164601145935, 'n_estimators': 830, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.7406617499906318, 'colsample_bytree': 0.7744814522700962, 'gamma': 0.6339108805162424, 'lambda': 1.5064074700495567}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:52:31,291] Trial 277 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.7328125541193, 'learning_rate': 0.14240425261631146, 'n_estimators': 658, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8602142400326294, 'colsample_bytree': 0.9693348699927006, 'gamma': 0.5886930915057108, 'lambda': 0.9807859133662734}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:52:45,831] Trial 278 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.8315345708926277, 'learning_rate': 0.09741320773162523, 'n_estimators': 805, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8359791313984825, 'colsample_bytree': 0.8895868626745839, 'gamma': 0.534264877024604, 'lambda': 1.237185318033067}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:52:58,500] Trial 279 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.6696388318566644, 'learning_rate': 0.09381195274250545, 'n_estimators': 741, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8305886649550741, 'colsample_bytree': 0.8796855321120095, 'gamma': 0.5373802463717167, 'lambda': 1.2488994385158385}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:53:11,963] Trial 280 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.5773577461481679, 'learning_rate': 0.08927905340241091, 'n_estimators': 765, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8382588454747424, 'colsample_bytree': 0.9117578508083056, 'gamma': 0.5235276109232234, 'lambda': 1.2172912551634814}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:53:25,472] Trial 281 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.7839403585327369, 'learning_rate': 0.0948092297832486, 'n_estimators': 808, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.915082099337976, 'colsample_bytree': 0.8908297617358136, 'gamma': 0.5083666982043483, 'lambda': 1.366454996696257}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:53:38,249] Trial 282 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7497051738780638, 'learning_rate': 0.11056477127762632, 'n_estimators': 777, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8231647113861412, 'colsample_bytree': 0.9028441696911983, 'gamma': 0.5570273187610785, 'lambda': 2.9444688327747963}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:53:51,106] Trial 283 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.7253599805175128, 'learning_rate': 0.09281952408564909, 'n_estimators': 735, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8117531853351172, 'colsample_bytree': 0.7913697918496783, 'gamma': 0.542156116131295, 'lambda': 1.3020848671769372}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:54:05,493] Trial 284 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.7613451087675784, 'learning_rate': 0.06874811427878863, 'n_estimators': 845, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8353957153711001, 'colsample_bytree': 0.7069935972966434, 'gamma': 0.793546774359822, 'lambda': 1.57717738359819}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:54:16,869] Trial 285 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.8359587309556011, 'learning_rate': 0.12858544676684092, 'n_estimators': 699, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.9282412056190815, 'colsample_bytree': 0.9474048693502574, 'gamma': 0.4595699349601163, 'lambda': 1.153811715028041}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:54:29,061] Trial 286 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.807969642741428, 'learning_rate': 0.10071680852307859, 'n_estimators': 760, 'max_depth': 18, 'min_child_weight': 5, 'subsample': 0.9105338346847854, 'colsample_bytree': 0.7662239162566127, 'gamma': 0.5995266682864397, 'lambda': 1.264502581867273}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:54:40,966] Trial 287 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.4759088325623913, 'learning_rate': 0.1185553339733041, 'n_estimators': 805, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8490315900689084, 'colsample_bytree': 0.7500739120615744, 'gamma': 0.6928369516742655, 'lambda': 1.6425034729234511}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:54:54,136] Trial 288 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.6917445277531048, 'learning_rate': 0.07677988423027954, 'n_estimators': 680, 'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.8856552255750771, 'colsample_bytree': 0.8889430585868126, 'gamma': 0.5698760574494758, 'lambda': 1.7213051839656044}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:55:12,066] Trial 289 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.7354810758190896, 'learning_rate': 0.04054768263003528, 'n_estimators': 722, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8139959506727411, 'colsample_bytree': 0.8537591829221697, 'gamma': 0.6709250065142759, 'lambda': 1.3472413197999813}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:55:26,066] Trial 290 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.7824794325481986, 'learning_rate': 0.08252886115380138, 'n_estimators': 870, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9007679603619428, 'colsample_bytree': 0.7846604171728877, 'gamma': 0.6284038055694336, 'lambda': 1.193821167708443}. Best is trial 150 with value: 0.9281786941580757.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:55:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 11:55:34,088] Trial 291 finished with value: 0.8092783505154642 and parameters: {'booster': 'gblinear', 'eta': 0.7160044524441825, 'learning_rate': 0.02497196685164548, 'n_estimators': 779, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.9065075790414198, 'colsample_bytree': 0.8685822399377651, 'gamma': 0.5287461066599222, 'lambda': 1.1164944610708707}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:55:48,840] Trial 292 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.6145952429547982, 'learning_rate': 0.06496685865078734, 'n_estimators': 749, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.9198259571169236, 'colsample_bytree': 0.9614474264244843, 'gamma': 0.4984420559179208, 'lambda': 1.2251476898488056}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:56:09,506] Trial 293 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.7578600891270868, 'learning_rate': 0.028933438197956945, 'n_estimators': 794, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.8930227013325652, 'colsample_bytree': 0.9386763102452006, 'gamma': 0.7382074801602718, 'lambda': 1.167436946712799}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:56:18,784] Trial 294 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.6514362525925327, 'learning_rate': 0.23888902125131484, 'n_estimators': 731, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8391687856444119, 'colsample_bytree': 0.9164164003999486, 'gamma': 0.9413262275584029, 'lambda': 1.2985246213314066}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:56:34,257] Trial 295 finished with value: 0.9195876288659794 and parameters: {'booster': 'gbtree', 'eta': 0.6721512246790641, 'learning_rate': 0.05964694000534828, 'n_estimators': 763, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.7913251480875428, 'colsample_bytree': 0.92803597338069, 'gamma': 0.5923571341210392, 'lambda': 1.1022976554533233}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:56:47,125] Trial 296 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.7957388001825356, 'learning_rate': 0.08676521059447752, 'n_estimators': 830, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8793071916144346, 'colsample_bytree': 0.8095204296299887, 'gamma': 0.92532614070131, 'lambda': 1.505416226103447}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:56:59,555] Trial 297 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.8511935826047915, 'learning_rate': 0.09670645406571637, 'n_estimators': 709, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.895126907729676, 'colsample_bytree': 0.9763779733391462, 'gamma': 0.5537166756219589, 'lambda': 1.4329472807414694}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:57:09,344] Trial 298 finished with value: 0.9182130584192442 and parameters: {'booster': 'gbtree', 'eta': 0.7069790981720926, 'learning_rate': 0.2974409408372978, 'n_estimators': 786, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8278939870540325, 'colsample_bytree': 0.9554888884578815, 'gamma': 0.9735611824840521, 'lambda': 1.0533423104531068}. Best is trial 150 with value: 0.9281786941580757.
[I 2024-06-06 11:57:24,835] Trial 299 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.8185438964584123, 'learning_rate': 0.05304800780955498, 'n_estimators': 815, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.8586708027801072, 'colsample_bytree': 0.8247040833147647, 'gamma': 0.9000173510726259, 'lambda': 1.2513222163715707}. Best is trial 150 with value: 0.9281786941580757.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:57:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "class_weight" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [11:57:26] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "class_weight" } are not used.

  warnings.warn(smsg, UserWarning)
