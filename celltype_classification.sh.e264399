[I 2024-06-06 14:24:33,703] A new study created in memory with name: no-name-fa3b4aec-3faf-477e-a2d2-edbafeb60f8a
[I 2024-06-06 14:25:27,017] Trial 0 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.7945125703137097, 'learning_rate': 0.1142324627566536, 'n_estimators': 1537, 'max_depth': 20, 'min_child_weight': 7, 'subsample': 0.8874924308115564, 'colsample_bytree': 0.9284434417946181, 'gamma': 0.6866487786511546, 'lambda': 1.4232967351193202}. Best is trial 0 with value: 0.9226804123711342.
[I 2024-06-06 14:25:46,269] Trial 1 finished with value: 0.9189003436426119 and parameters: {'booster': 'gbtree', 'eta': 0.3447821693809096, 'learning_rate': 0.048572469180444444, 'n_estimators': 1212, 'max_depth': 14, 'min_child_weight': 9, 'subsample': 0.786982510507496, 'colsample_bytree': 0.5319290752237806, 'gamma': 0.48772666281521926, 'lambda': 1.4339276109578285}. Best is trial 0 with value: 0.9226804123711342.
[I 2024-06-06 14:26:01,477] Trial 2 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.0659229774295673, 'learning_rate': 0.04372404870555835, 'n_estimators': 816, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.6375753649671023, 'colsample_bytree': 0.6763705527517583, 'gamma': 0.6673511891451694, 'lambda': 2.9184005079354947}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:26:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:26:15,653] Trial 3 finished with value: 0.8068728522336772 and parameters: {'booster': 'gblinear', 'eta': 0.14213004033203877, 'learning_rate': 0.2104526345205295, 'n_estimators': 1867, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.5172324091645629, 'colsample_bytree': 0.9910929516408724, 'gamma': 0.5170611144449446, 'lambda': 1.539096573991072}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:26:28,392] Trial 4 finished with value: 0.9130584192439863 and parameters: {'booster': 'gbtree', 'eta': 0.6829254366328185, 'learning_rate': 0.13590403206678442, 'n_estimators': 991, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.8205316499289057, 'colsample_bytree': 0.7361188039604054, 'gamma': 0.4603463178961503, 'lambda': 2.135545227921157}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:26:43,496] Trial 5 finished with value: 0.9206185567010311 and parameters: {'booster': 'gbtree', 'eta': 0.04581348175439283, 'learning_rate': 0.14490239641771901, 'n_estimators': 1147, 'max_depth': 18, 'min_child_weight': 3, 'subsample': 0.5504156430198281, 'colsample_bytree': 0.8442199233479148, 'gamma': 0.3021211611594534, 'lambda': 1.9767799785704219}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:27:03,251] Trial 6 finished with value: 0.9072164948453609 and parameters: {'booster': 'gbtree', 'eta': 0.6543161548786968, 'learning_rate': 0.08776124436373413, 'n_estimators': 1175, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.5217231940489427, 'colsample_bytree': 0.6171853078582458, 'gamma': 0.438185748762292, 'lambda': 2.0307914910513167}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:27:08,764] Trial 7 finished with value: 0.8058419243986256 and parameters: {'booster': 'gblinear', 'eta': 0.6202593329483614, 'learning_rate': 0.1601372959631372, 'n_estimators': 732, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6445750815829713, 'colsample_bytree': 0.8510153362645666, 'gamma': 0.8014355103645651, 'lambda': 2.0449212318749685}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:27:19,188] Trial 8 finished with value: 0.8058419243986256 and parameters: {'booster': 'gblinear', 'eta': 0.9978774836335866, 'learning_rate': 0.20490602044562076, 'n_estimators': 1396, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8766429884207952, 'colsample_bytree': 0.5410897176487603, 'gamma': 0.03890017073488583, 'lambda': 2.046217898921753}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:27:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:27:23,135] Trial 9 finished with value: 0.8037800687285225 and parameters: {'booster': 'gblinear', 'eta': 0.5026427438625933, 'learning_rate': 0.07064169977878208, 'n_estimators': 522, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.845083490963219, 'colsample_bytree': 0.5574340318032897, 'gamma': 0.3621373562380965, 'lambda': 2.4769207298612175}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:28:19,672] Trial 10 finished with value: 0.8907216494845362 and parameters: {'booster': 'gbtree', 'eta': 0.22644920046690753, 'learning_rate': 0.0015389369945185902, 'n_estimators': 831, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.9796205955105346, 'colsample_bytree': 0.6768598805928009, 'gamma': 0.9066302410814161, 'lambda': 2.9494786650010543}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:28:37,971] Trial 11 finished with value: 0.911683848797251 and parameters: {'booster': 'gbtree', 'eta': 0.31133285709722414, 'learning_rate': 0.25063503639919493, 'n_estimators': 1947, 'max_depth': 20, 'min_child_weight': 7, 'subsample': 0.6922746028192115, 'colsample_bytree': 0.7912683326342249, 'gamma': 0.6904271584576145, 'lambda': 0.8701837663215758}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:28:53,767] Trial 12 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.1032501987499786, 'learning_rate': 0.09428071852251085, 'n_estimators': 1545, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.7147990412047225, 'colsample_bytree': 0.9753782181981581, 'gamma': 0.9981809425983654, 'lambda': 2.968775867976441}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:29:09,305] Trial 13 finished with value: 0.923024054982818 and parameters: {'booster': 'gbtree', 'eta': 0.06301319533313773, 'learning_rate': 0.030419257042589055, 'n_estimators': 895, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.7102646086058214, 'colsample_bytree': 0.6999244740469279, 'gamma': 0.9925065715178504, 'lambda': 2.982051155887002}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:29:51,586] Trial 14 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.17536209338757391, 'learning_rate': 0.08789881809286174, 'n_estimators': 716, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.6312181672019195, 'colsample_bytree': 0.6578351890896935, 'gamma': 0.9947207296985751, 'lambda': 2.5734032217733436}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:30:11,540] Trial 15 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.024188484622499812, 'learning_rate': 0.03975222131190265, 'n_estimators': 1577, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.7502910108316545, 'colsample_bytree': 0.7751297150069618, 'gamma': 0.81902681450979, 'lambda': 2.6391903545475754}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:30:55,773] Trial 16 finished with value: 0.8759450171821307 and parameters: {'booster': 'gbtree', 'eta': 0.24417362853405394, 'learning_rate': 0.0012849458219322818, 'n_estimators': 1349, 'max_depth': 13, 'min_child_weight': 4, 'subsample': 0.5963902494619143, 'colsample_bytree': 0.9993868400672467, 'gamma': 0.7014788707933298, 'lambda': 2.9964835944583847}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:31:05,126] Trial 17 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.35856933402591434, 'learning_rate': 0.29952592972880454, 'n_estimators': 982, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.6899488804197162, 'colsample_bytree': 0.8941267834967506, 'gamma': 0.8454713040956838, 'lambda': 2.3974616413323}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:06] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:31:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:31:12,572] Trial 18 finished with value: 0.8037800687285225 and parameters: {'booster': 'gblinear', 'eta': 0.38890979882376797, 'learning_rate': 0.28168845943796256, 'n_estimators': 1011, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.5852274266962803, 'colsample_bytree': 0.615001024328879, 'gamma': 0.608874033503078, 'lambda': 2.354100699388007}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:31:19,393] Trial 19 finished with value: 0.9182130584192442 and parameters: {'booster': 'gbtree', 'eta': 0.42378598182736543, 'learning_rate': 0.2842073597025518, 'n_estimators': 646, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.638274276160283, 'colsample_bytree': 0.8770912104888453, 'gamma': 0.8265295067148317, 'lambda': 2.7037366870577975}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:31:29,127] Trial 20 finished with value: 0.9192439862542957 and parameters: {'booster': 'gbtree', 'eta': 0.2557210773153331, 'learning_rate': 0.1798590342875241, 'n_estimators': 872, 'max_depth': 13, 'min_child_weight': 4, 'subsample': 0.6739149379078477, 'colsample_bytree': 0.735069164203489, 'gamma': 0.6055987976053012, 'lambda': 2.292380138386746}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:31:40,337] Trial 21 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.14014205334302782, 'learning_rate': 0.11151828856051732, 'n_estimators': 986, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.72315985086323, 'colsample_bytree': 0.927693125316167, 'gamma': 0.891323125095635, 'lambda': 2.768776172048548}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:31:50,648] Trial 22 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.11580561553343632, 'learning_rate': 0.2566915382359933, 'n_estimators': 1086, 'max_depth': 18, 'min_child_weight': 4, 'subsample': 0.7541977713172785, 'colsample_bytree': 0.938544471436023, 'gamma': 0.9043489992929284, 'lambda': 2.7556385738355567}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:32:06,192] Trial 23 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.20298972885114014, 'learning_rate': 0.06820531914756511, 'n_estimators': 1281, 'max_depth': 19, 'min_child_weight': 2, 'subsample': 0.6747588740905103, 'colsample_bytree': 0.959270431062445, 'gamma': 0.7608061909567769, 'lambda': 2.5130565359442776}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:32:17,727] Trial 24 finished with value: 0.9209621993127148 and parameters: {'booster': 'gbtree', 'eta': 0.031253795163419966, 'learning_rate': 0.12156579996786741, 'n_estimators': 1084, 'max_depth': 16, 'min_child_weight': 3, 'subsample': 0.7286452178313981, 'colsample_bytree': 0.8941696477211893, 'gamma': 0.9155230988446798, 'lambda': 2.8304025900583585}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:32:27,250] Trial 25 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.2922114221687883, 'learning_rate': 0.16908642497384235, 'n_estimators': 909, 'max_depth': 17, 'min_child_weight': 1, 'subsample': 0.6012790439407572, 'colsample_bytree': 0.8057512116847876, 'gamma': 0.9848026172349136, 'lambda': 2.3972195116346655}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:32:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:32:33,129] Trial 26 finished with value: 0.8037800687285225 and parameters: {'booster': 'gblinear', 'eta': 0.30699749628028417, 'learning_rate': 0.1637749995150959, 'n_estimators': 805, 'max_depth': 16, 'min_child_weight': 1, 'subsample': 0.604038462631001, 'colsample_bytree': 0.8077579567720858, 'gamma': 0.8492171599898403, 'lambda': 2.37181301772217}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:32:43,026] Trial 27 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.4236588798422391, 'learning_rate': 0.1947110936332169, 'n_estimators': 945, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.5625433815980343, 'colsample_bytree': 0.8161732115049949, 'gamma': 0.7918316716038268, 'lambda': 2.5095725455000584}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:32:52,147] Trial 28 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.2906968483681313, 'learning_rate': 0.22457180530558635, 'n_estimators': 898, 'max_depth': 18, 'min_child_weight': 1, 'subsample': 0.6593134054462225, 'colsample_bytree': 0.7712369568523596, 'gamma': 0.7550816110464761, 'lambda': 2.24748927685063}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:33:01,803] Trial 29 finished with value: 0.9151202749140894 and parameters: {'booster': 'gbtree', 'eta': 0.17706771529774362, 'learning_rate': 0.17439021915309064, 'n_estimators': 779, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.6117616753609811, 'colsample_bytree': 0.907685478969733, 'gamma': 0.6409959593900761, 'lambda': 1.820139575758564}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:33:12,673] Trial 30 finished with value: 0.9147766323024056 and parameters: {'booster': 'gbtree', 'eta': 0.3556858587065368, 'learning_rate': 0.2972429897692508, 'n_estimators': 1045, 'max_depth': 19, 'min_child_weight': 4, 'subsample': 0.5625552202298081, 'colsample_bytree': 0.8341704609442873, 'gamma': 0.7337103667946867, 'lambda': 2.6778015606399617}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:33:23,621] Trial 31 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.10325118978789241, 'learning_rate': 0.11586777258907498, 'n_estimators': 951, 'max_depth': 20, 'min_child_weight': 2, 'subsample': 0.6795135677187092, 'colsample_bytree': 0.8890040476712537, 'gamma': 0.9936446321847013, 'lambda': 2.835248674769659}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:33:35,627] Trial 32 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.10884575250311312, 'learning_rate': 0.22945115854372244, 'n_estimators': 1197, 'max_depth': 20, 'min_child_weight': 3, 'subsample': 0.6312158345178385, 'colsample_bytree': 0.9581819561362017, 'gamma': 0.9527197426819229, 'lambda': 2.839805222915733}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:33:51,431] Trial 33 finished with value: 0.9213058419243988 and parameters: {'booster': 'gbtree', 'eta': 0.21146869426203235, 'learning_rate': 0.1795008326596591, 'n_estimators': 1627, 'max_depth': 17, 'min_child_weight': 1, 'subsample': 0.7017379347388298, 'colsample_bytree': 0.9712207048521754, 'gamma': 0.8756316085921468, 'lambda': 2.451778135220865}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:34:09,263] Trial 34 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.011543342520200617, 'learning_rate': 0.1285609235387754, 'n_estimators': 1717, 'max_depth': 19, 'min_child_weight': 2, 'subsample': 0.6530422819878534, 'colsample_bytree': 0.8562201028659799, 'gamma': 0.8631198827289513, 'lambda': 2.6085079981413712}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:34:24,408] Trial 35 finished with value: 0.9158075601374571 and parameters: {'booster': 'gbtree', 'eta': 0.16624321729158437, 'learning_rate': 0.14687600878922952, 'n_estimators': 1450, 'max_depth': 14, 'min_child_weight': 9, 'subsample': 0.7805893169140031, 'colsample_bytree': 0.9248928694353727, 'gamma': 0.9388995129483485, 'lambda': 2.253879952763463}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:46:07,645] Trial 36 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.0877071231895254, 'learning_rate': 0.1391966564794815, 'n_estimators': 1258, 'max_depth': 17, 'min_child_weight': 3, 'subsample': 0.702911689622076, 'colsample_bytree': 0.8721755827418524, 'gamma': 0.9381411652265388, 'lambda': 2.883467299344058}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:07] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:46:15,831] Trial 37 finished with value: 0.8034364261168387 and parameters: {'booster': 'gblinear', 'eta': 0.2748583200173005, 'learning_rate': 0.10593671143943639, 'n_estimators': 1125, 'max_depth': 19, 'min_child_weight': 1, 'subsample': 0.5081305379559014, 'colsample_bytree': 0.9867029783443129, 'gamma': 0.8530470184089018, 'lambda': 2.6770742659597393}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:46:27,350] Trial 38 finished with value: 0.916151202749141 and parameters: {'booster': 'gbtree', 'eta': 0.13936996432421964, 'learning_rate': 0.15296075931959632, 'n_estimators': 1032, 'max_depth': 15, 'min_child_weight': 6, 'subsample': 0.6631797573329259, 'colsample_bytree': 0.8274862705391922, 'gamma': 0.7786865059281256, 'lambda': 2.1465250970452368}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:27] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:34] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:35] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:46:35] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:46:36,189] Trial 39 finished with value: 0.8061855670103095 and parameters: {'booster': 'gblinear', 'eta': 0.07378410582688345, 'learning_rate': 0.058929263419093186, 'n_estimators': 1199, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.538109851297886, 'colsample_bytree': 0.8618315599976547, 'gamma': 0.8281611339134405, 'lambda': 1.9078171388272658}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:46:52,885] Trial 40 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.34050211865460545, 'learning_rate': 0.08011454765317925, 'n_estimators': 1499, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.5774880800655439, 'colsample_bytree': 0.9023521818887725, 'gamma': 0.9610271302450167, 'lambda': 1.582314153301174}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:47:02,452] Trial 41 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.16392004957507283, 'learning_rate': 0.09593363648897574, 'n_estimators': 740, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.6032405735423788, 'colsample_bytree': 0.6695020707484902, 'gamma': 0.990962497048926, 'lambda': 2.6103002452485966}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:52:54,760] Trial 42 finished with value: 0.9202749140893471 and parameters: {'booster': 'gbtree', 'eta': 0.22861354475464457, 'learning_rate': 0.09093358017088274, 'n_estimators': 846, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.6150091484399004, 'colsample_bytree': 0.7444226740108434, 'gamma': 0.9952120937102212, 'lambda': 2.8782502052445182}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:53:05,977] Trial 43 finished with value: 0.920618556701031 and parameters: {'booster': 'gbtree', 'eta': 0.17987311531772388, 'learning_rate': 0.10143175725287457, 'n_estimators': 932, 'max_depth': 15, 'min_child_weight': 5, 'subsample': 0.6214577313053085, 'colsample_bytree': 0.7269881740440814, 'gamma': 0.9358409865613332, 'lambda': 2.451423749338413}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:53:14,011] Trial 44 finished with value: 0.9195876288659796 and parameters: {'booster': 'gbtree', 'eta': 0.052950327176966364, 'learning_rate': 0.13444258357887856, 'n_estimators': 778, 'max_depth': 2, 'min_child_weight': 1, 'subsample': 0.6499389680666371, 'colsample_bytree': 0.7116949036249219, 'gamma': 0.9072274705709311, 'lambda': 2.6082962685326256}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:53:26,085] Trial 45 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.1381814140032896, 'learning_rate': 0.0496187731381558, 'n_estimators': 710, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.5882184445328389, 'colsample_bytree': 0.8006718618055436, 'gamma': 0.8839809521520349, 'lambda': 2.992567036941815}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:53:42,048] Trial 46 finished with value: 0.9130584192439863 and parameters: {'booster': 'gbtree', 'eta': 0.2572220190064247, 'learning_rate': 0.02167193504834042, 'n_estimators': 863, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6798959954828322, 'colsample_bytree': 0.7607366597150703, 'gamma': 0.976367053182556, 'lambda': 2.7521944261123363}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:42] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:43] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:44] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:45] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:46] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:47] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [14:53:49] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 14:53:50,218] Trial 47 finished with value: 0.8034364261168387 and parameters: {'booster': 'gblinear', 'eta': 0.07719987550508012, 'learning_rate': 0.0744208904676002, 'n_estimators': 1118, 'max_depth': 17, 'min_child_weight': 2, 'subsample': 0.5270080121295265, 'colsample_bytree': 0.670109373225051, 'gamma': 0.9432840113864505, 'lambda': 2.552264026674147}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:54:02,756] Trial 48 finished with value: 0.9151202749140894 and parameters: {'booster': 'gbtree', 'eta': 0.19742317943117116, 'learning_rate': 0.09177038461156889, 'n_estimators': 914, 'max_depth': 20, 'min_child_weight': 8, 'subsample': 0.6325932749418821, 'colsample_bytree': 0.7811797001399607, 'gamma': 0.8225349447278678, 'lambda': 2.15321256526175}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 14:54:23,865] Trial 49 finished with value: 0.914089347079038 and parameters: {'booster': 'gbtree', 'eta': 0.27740092879613304, 'learning_rate': 0.1005734691368605, 'n_estimators': 1832, 'max_depth': 19, 'min_child_weight': 4, 'subsample': 0.5449395327494454, 'colsample_bytree': 0.8445044890700181, 'gamma': 0.7210953330651618, 'lambda': 2.9102027479141275}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:08:04,835] Trial 50 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.22642026932850695, 'learning_rate': 0.052920768600353794, 'n_estimators': 820, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.6007907228978513, 'colsample_bytree': 0.6400817697938673, 'gamma': 0.9960263025868307, 'lambda': 2.3796010521572213}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:08:14,605] Trial 51 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.15813200271908073, 'learning_rate': 0.08272757811443784, 'n_estimators': 703, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.6444399177694351, 'colsample_bytree': 0.7009039698592232, 'gamma': 0.9969003565188786, 'lambda': 2.547348008758219}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:08:22,957] Trial 52 finished with value: 0.920962199312715 and parameters: {'booster': 'gbtree', 'eta': 0.1315873563934432, 'learning_rate': 0.12310543490646547, 'n_estimators': 651, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6295969308392552, 'colsample_bytree': 0.6790648783697862, 'gamma': 0.9060053218457367, 'lambda': 2.697083101444023}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:08:33,871] Trial 53 finished with value: 0.9216494845360825 and parameters: {'booster': 'gbtree', 'eta': 0.04640378247174216, 'learning_rate': 0.06355637253751181, 'n_estimators': 754, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.6877220282350447, 'colsample_bytree': 0.6375477474272873, 'gamma': 0.9651184953876536, 'lambda': 2.60853082420516}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:08:49,342] Trial 54 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.1782399062349917, 'learning_rate': 0.03776890223248165, 'n_estimators': 832, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.570753806324175, 'colsample_bytree': 0.760591184766734, 'gamma': 0.8597264969207735, 'lambda': 2.7828564280362404}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:12:21,320] Trial 55 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.10179253858466447, 'learning_rate': 0.06888884994612912, 'n_estimators': 978, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5738322822909332, 'colsample_bytree': 0.7610893716882461, 'gamma': 0.8064042925963448, 'lambda': 2.7920105410001015}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:12:37,034] Trial 56 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.3264983050063297, 'learning_rate': 0.046903453734214916, 'n_estimators': 977, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5701527645598592, 'colsample_bytree': 0.7537693001321277, 'gamma': 0.8151903902818456, 'lambda': 2.7491970147619798}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:20:01,575] Trial 57 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.23639870431811472, 'learning_rate': 0.03296950870939585, 'n_estimators': 856, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5818314475722441, 'colsample_bytree': 0.7916173739102722, 'gamma': 0.7884739096566498, 'lambda': 2.7903333239902564}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:20:18,831] Trial 58 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.24497058766696136, 'learning_rate': 0.03297742460692, 'n_estimators': 870, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5951478493759257, 'colsample_bytree': 0.7923640907708147, 'gamma': 0.774255838525138, 'lambda': 2.43526602521609}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:20:25] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 15:20:25,497] Trial 59 finished with value: 0.8041237113402063 and parameters: {'booster': 'gblinear', 'eta': 0.2995489616924991, 'learning_rate': 0.019625350434464686, 'n_estimators': 876, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5246676344152627, 'colsample_bytree': 0.7881663024565748, 'gamma': 0.6708113923460773, 'lambda': 2.4378842009428396}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:20:42,035] Trial 60 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.2486881324936682, 'learning_rate': 0.035060124054232485, 'n_estimators': 847, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.591283703770293, 'colsample_bytree': 0.8165988624252271, 'gamma': 0.7477657593668471, 'lambda': 2.3198433098357594}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:20:58,009] Trial 61 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.24165739651593926, 'learning_rate': 0.037532600762460816, 'n_estimators': 825, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5874116738967546, 'colsample_bytree': 0.8142969291526301, 'gamma': 0.7438056905828864, 'lambda': 2.2423393695892435}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:21:17,552] Trial 62 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.25140552330004745, 'learning_rate': 0.025980256465484658, 'n_estimators': 830, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.5488845794370021, 'colsample_bytree': 0.8243791344985263, 'gamma': 0.7582617831450988, 'lambda': 2.2720714260975376}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:21:42,911] Trial 63 finished with value: 0.9240549828178696 and parameters: {'booster': 'gbtree', 'eta': 0.21654181848468784, 'learning_rate': 0.012927988765934024, 'n_estimators': 798, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.5446942594672781, 'colsample_bytree': 0.7880384871545377, 'gamma': 0.7057550565233696, 'lambda': 2.1930318278831424}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:21:58,856] Trial 64 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.35209043042243926, 'learning_rate': 0.039263169720410766, 'n_estimators': 831, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5586739241571131, 'colsample_bytree': 0.8412237536092914, 'gamma': 0.7779509624646267, 'lambda': 2.0744015109127862}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:22:14,723] Trial 65 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.3690924249628885, 'learning_rate': 0.03958419963435941, 'n_estimators': 802, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.5593285756290628, 'colsample_bytree': 0.833687290958063, 'gamma': 0.7406391679278296, 'lambda': 2.035950979740627}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:22:30,759] Trial 66 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.36571303679112854, 'learning_rate': 0.04115423270591287, 'n_estimators': 802, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.508008966281215, 'colsample_bytree': 0.8328140836959842, 'gamma': 0.6740579891502632, 'lambda': 1.9579662543661345}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:22:44,792] Trial 67 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.38368838704277336, 'learning_rate': 0.05978256997446493, 'n_estimators': 905, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.5502913965805375, 'colsample_bytree': 0.8482897578180348, 'gamma': 0.7350949586914435, 'lambda': 2.3001315788089425}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:22:59,936] Trial 68 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.4474291461693232, 'learning_rate': 0.041436144585329356, 'n_estimators': 820, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.5625616390481863, 'colsample_bytree': 0.8678607624448391, 'gamma': 0.7658140097176576, 'lambda': 2.118819675436635}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:23:19,260] Trial 69 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.32816492784957657, 'learning_rate': 0.025983191088227206, 'n_estimators': 764, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.5370603610618202, 'colsample_bytree': 0.8227597366426719, 'gamma': 0.7080354380950888, 'lambda': 2.059631592406401}. Best is trial 2 with value: 0.9271477663230242.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:19] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:20] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:21] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:23:24] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 15:23:25,265] Trial 70 finished with value: 0.8054982817869417 and parameters: {'booster': 'gblinear', 'eta': 0.31737360566373296, 'learning_rate': 0.025769384675392908, 'n_estimators': 759, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.5318996379547034, 'colsample_bytree': 0.8178666299020522, 'gamma': 0.6989423357711922, 'lambda': 2.031788419727708}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:24:00,929] Trial 71 finished with value: 0.9195876288659796 and parameters: {'booster': 'gbtree', 'eta': 0.3364075412453805, 'learning_rate': 0.0072841289506083914, 'n_estimators': 819, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5576261902923579, 'colsample_bytree': 0.8455743470124513, 'gamma': 0.7320990084582096, 'lambda': 2.0821631429925542}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:24:23,909] Trial 72 finished with value: 0.9216494845360826 and parameters: {'booster': 'gbtree', 'eta': 0.39147891751022773, 'learning_rate': 0.014636293050808328, 'n_estimators': 766, 'max_depth': 16, 'min_child_weight': 2, 'subsample': 0.520729150450675, 'colsample_bytree': 0.8221725776867417, 'gamma': 0.8476511149635392, 'lambda': 2.2048759588819573}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:24:43,581] Trial 73 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.2766234742240666, 'learning_rate': 0.025721681151147223, 'n_estimators': 730, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.5537134881101192, 'colsample_bytree': 0.8806972992530367, 'gamma': 0.623942930175543, 'lambda': 2.066980230000019}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:25:02,059] Trial 74 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.27270324282463115, 'learning_rate': 0.028584201584733432, 'n_estimators': 728, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5002035046043539, 'colsample_bytree': 0.8330742363035778, 'gamma': 0.6410249980660325, 'lambda': 2.0464385085926877}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:25:40,505] Trial 75 finished with value: 0.8855670103092785 and parameters: {'booster': 'gbtree', 'eta': 0.2789160431185336, 'learning_rate': 0.0014641440189560526, 'n_estimators': 725, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.5014303258754872, 'colsample_bytree': 0.8768889251357949, 'gamma': 0.6135013518566068, 'lambda': 1.989743613684322}. Best is trial 2 with value: 0.9271477663230242.
[I 2024-06-06 15:25:59,145] Trial 76 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.326116293231984, 'learning_rate': 0.027779198384667823, 'n_estimators': 682, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5382955598042936, 'colsample_bytree': 0.8578900985864643, 'gamma': 0.5674282070814266, 'lambda': 2.086322820158436}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:26:24,883] Trial 77 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.3020085028050934, 'learning_rate': 0.014588556410985071, 'n_estimators': 700, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5178939052486478, 'colsample_bytree': 0.8582142838765962, 'gamma': 0.5596399292960685, 'lambda': 1.8887635876318736}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:29:00,229] Trial 78 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.26597829984142024, 'learning_rate': 0.027679040487513566, 'n_estimators': 671, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.536790293052895, 'colsample_bytree': 0.8364545221850539, 'gamma': 0.6432402984804415, 'lambda': 1.7813999379776804}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:36:32,823] Trial 79 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.2612808993277976, 'learning_rate': 0.025468293382787152, 'n_estimators': 678, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5373086929014204, 'colsample_bytree': 0.8858272082355949, 'gamma': 0.6338146517762379, 'lambda': 1.7098832092199463}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:36:46,546] Trial 80 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.19984463602474764, 'learning_rate': 0.05321696301019194, 'n_estimators': 680, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.5002013687319967, 'colsample_bytree': 0.8828886554251147, 'gamma': 0.652416752430921, 'lambda': 1.7610346333576115}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:37:04,138] Trial 81 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.26003228012092605, 'learning_rate': 0.026869092114332235, 'n_estimators': 624, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5361962006136112, 'colsample_bytree': 0.8602505204785199, 'gamma': 0.579410361998938, 'lambda': 1.6622458677039567}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:37:30,245] Trial 82 finished with value: 0.9189003436426119 and parameters: {'booster': 'gbtree', 'eta': 0.27351110954778307, 'learning_rate': 0.00968013189520436, 'n_estimators': 618, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5367413263284502, 'colsample_bytree': 0.864013312535094, 'gamma': 0.5838780743112301, 'lambda': 1.667261337645966}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:37:49,941] Trial 83 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.3003374277140006, 'learning_rate': 0.02085697209775914, 'n_estimators': 614, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5333175518847766, 'colsample_bytree': 0.8869549099069038, 'gamma': 0.64733616833157, 'lambda': 1.8065619884982478}. Best is trial 76 with value: 0.9281786941580757.
[I 2024-06-06 15:38:07,390] Trial 84 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.27245011233089284, 'learning_rate': 0.03129672317762004, 'n_estimators': 678, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5191279819118084, 'colsample_bytree': 0.8545485409260953, 'gamma': 0.5381598225598128, 'lambda': 1.8593228094621}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:38:25,385] Trial 85 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.2651471094463096, 'learning_rate': 0.026587251440907084, 'n_estimators': 670, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.5154276628577849, 'colsample_bytree': 0.9150412556078862, 'gamma': 0.5237549364004722, 'lambda': 1.691728813781441}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:38:40,166] Trial 86 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.2053423221031073, 'learning_rate': 0.045872075517410474, 'n_estimators': 733, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.5119694518378788, 'colsample_bytree': 0.9002178097541368, 'gamma': 0.6227870086795929, 'lambda': 1.8495222050289624}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:40:51,692] Trial 87 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.325443456711659, 'learning_rate': 0.02960847202477192, 'n_estimators': 626, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5232635671854896, 'colsample_bytree': 0.8695595726542207, 'gamma': 0.5568573313365263, 'lambda': 1.9483004239254904}. Best is trial 84 with value: 0.9285223367697596.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:51] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:40:56] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 15:40:56,473] Trial 88 finished with value: 0.8068728522336772 and parameters: {'booster': 'gblinear', 'eta': 0.2913516017930719, 'learning_rate': 0.006409745535870905, 'n_estimators': 598, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5520800222133397, 'colsample_bytree': 0.8543389636695163, 'gamma': 0.5865226807114103, 'lambda': 1.4456690153681484}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:41:17,376] Trial 89 finished with value: 0.9226804123711342 and parameters: {'booster': 'gbtree', 'eta': 0.36842062765966366, 'learning_rate': 0.017396273083879123, 'n_estimators': 672, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.5337625310050883, 'colsample_bytree': 0.8360942873817726, 'gamma': 0.6314339397645025, 'lambda': 1.9982303607833454}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:41:29,785] Trial 90 finished with value: 0.9120274914089348 and parameters: {'booster': 'gbtree', 'eta': 0.2658650067146971, 'learning_rate': 0.0531928881308688, 'n_estimators': 693, 'max_depth': 13, 'min_child_weight': 7, 'subsample': 0.5106113361040648, 'colsample_bytree': 0.9131326808362541, 'gamma': 0.6642347433905911, 'lambda': 1.8885577557776723}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:41:45,697] Trial 91 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.21498390239968623, 'learning_rate': 0.03564464506039694, 'n_estimators': 719, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5432342639351916, 'colsample_bytree': 0.8843386946698735, 'gamma': 0.6839700181472528, 'lambda': 1.9428649695284064}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:42:00,235] Trial 92 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.3111099671887399, 'learning_rate': 0.04494472762749255, 'n_estimators': 745, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.5685884665407775, 'colsample_bytree': 0.8515884801455219, 'gamma': 0.6254217532257133, 'lambda': 1.7742754208152363}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:42:14,972] Trial 93 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.30357653274895574, 'learning_rate': 0.04332165333999513, 'n_estimators': 742, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5631251860345116, 'colsample_bytree': 0.8532096593629417, 'gamma': 0.6338788554064564, 'lambda': 1.7900051411975673}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:49:22,177] Trial 94 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.3150351523231347, 'learning_rate': 0.047837911326012325, 'n_estimators': 745, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5676041260189498, 'colsample_bytree': 0.8528065147740523, 'gamma': 0.5896660878760233, 'lambda': 1.7911337023834064}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:49:29,467] Trial 95 finished with value: 0.8955326460481101 and parameters: {'booster': 'gbtree', 'eta': 0.31196834269496077, 'learning_rate': 0.062378329421028965, 'n_estimators': 744, 'max_depth': 1, 'min_child_weight': 2, 'subsample': 0.5670815007306893, 'colsample_bytree': 0.840108467958635, 'gamma': 0.5936848411651648, 'lambda': 1.8055361604988622}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:49:43,526] Trial 96 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.3414037931408377, 'learning_rate': 0.045019500475733415, 'n_estimators': 653, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5800294334933019, 'colsample_bytree': 0.848325276384874, 'gamma': 0.4887251049065142, 'lambda': 1.6216866060242041}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:49:57,033] Trial 97 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.34562866871911746, 'learning_rate': 0.048122463825666435, 'n_estimators': 647, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.5775215781493304, 'colsample_bytree': 0.8078902485153949, 'gamma': 0.485356081408085, 'lambda': 1.6219831044889452}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:50:09,783] Trial 98 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.3485688406249183, 'learning_rate': 0.05553515264708274, 'n_estimators': 644, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.5787262376999754, 'colsample_bytree': 0.8051736471061655, 'gamma': 0.47991398151667036, 'lambda': 1.6463518189325004}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:50:21,575] Trial 99 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.4034806353438886, 'learning_rate': 0.05612011350285567, 'n_estimators': 590, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.614028003132489, 'colsample_bytree': 0.8068247496309922, 'gamma': 0.5028431574592738, 'lambda': 1.6171043675864023}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:50:35,351] Trial 100 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.3537098101005766, 'learning_rate': 0.04938290116645916, 'n_estimators': 659, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.5831872681302793, 'colsample_bytree': 0.8034276224375265, 'gamma': 0.46274562141455305, 'lambda': 1.4991690743101767}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:50:52,211] Trial 101 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.3411789779090931, 'learning_rate': 0.032199060249598205, 'n_estimators': 650, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.5972007289955037, 'colsample_bytree': 0.8641445239775817, 'gamma': 0.4769912667222117, 'lambda': 1.6374458167146704}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:51:03,932] Trial 102 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.34621000812660835, 'learning_rate': 0.06654484527613477, 'n_estimators': 642, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5960057165341593, 'colsample_bytree': 0.8622909727709517, 'gamma': 0.47660311146326795, 'lambda': 1.59375860796112}. Best is trial 84 with value: 0.9285223367697596.
[I 2024-06-06 15:51:20,513] Trial 103 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.4115252464205468, 'learning_rate': 0.03404956330546046, 'n_estimators': 643, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.5785297763162832, 'colsample_bytree': 0.8326522924700022, 'gamma': 0.42106674135234334, 'lambda': 1.7242162368924496}. Best is trial 103 with value: 0.9288659793814434.
[I 2024-06-06 15:51:33,436] Trial 104 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.4114398751663817, 'learning_rate': 0.056373973293717905, 'n_estimators': 633, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.5760089517261097, 'colsample_bytree': 0.8743944242424614, 'gamma': 0.42109021151403164, 'lambda': 1.7182654069219345}. Best is trial 103 with value: 0.9288659793814434.
[I 2024-06-06 15:55:13,492] Trial 105 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.3380552766804682, 'learning_rate': 0.03155624417851655, 'n_estimators': 639, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.5802419558422475, 'colsample_bytree': 0.8430931690462607, 'gamma': 0.43833395887093085, 'lambda': 1.6363383350859575}. Best is trial 105 with value: 0.9292096219931273.
[I 2024-06-06 15:55:37,004] Trial 106 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.3844816248349985, 'learning_rate': 0.018837222923240568, 'n_estimators': 657, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.6112512914668141, 'colsample_bytree': 0.8442121740113957, 'gamma': 0.427366617937295, 'lambda': 1.5691823545400605}. Best is trial 105 with value: 0.9292096219931273.
[I 2024-06-06 15:56:28,947] Trial 107 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.37521666873805926, 'learning_rate': 0.01931283687357293, 'n_estimators': 576, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6084613837072456, 'colsample_bytree': 0.8448177979279925, 'gamma': 0.4317607682841399, 'lambda': 1.6560058195729255}. Best is trial 105 with value: 0.9292096219931273.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:28] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [15:56:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 15:56:33,444] Trial 108 finished with value: 0.8103092783505157 and parameters: {'booster': 'gblinear', 'eta': 0.3795809071077211, 'learning_rate': 0.015939295032237892, 'n_estimators': 571, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6078232159511419, 'colsample_bytree': 0.8424512086705557, 'gamma': 0.4309368304426219, 'lambda': 1.5563083001838753}. Best is trial 105 with value: 0.9292096219931273.
[I 2024-06-06 15:56:55,595] Trial 109 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.46490162585543415, 'learning_rate': 0.020366716271479925, 'n_estimators': 693, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.5820217137464712, 'colsample_bytree': 0.8278835052533995, 'gamma': 0.4072849381347746, 'lambda': 1.7259907997497863}. Best is trial 105 with value: 0.9292096219931273.
[I 2024-06-06 15:57:13,593] Trial 110 finished with value: 0.9202749140893471 and parameters: {'booster': 'gbtree', 'eta': 0.3993242307303875, 'learning_rate': 0.009538845163013229, 'n_estimators': 560, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6253671187741698, 'colsample_bytree': 0.8507969094497535, 'gamma': 0.4467271487271596, 'lambda': 1.5377945610515176}. Best is trial 105 with value: 0.9292096219931273.
[I 2024-06-06 15:57:28,105] Trial 111 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.3300716161711876, 'learning_rate': 0.035540192693507326, 'n_estimators': 657, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.5937785772012258, 'colsample_bytree': 0.8648823601835817, 'gamma': 0.5212430664903491, 'lambda': 1.6462491559246297}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 15:57:43,194] Trial 112 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.38286185482414176, 'learning_rate': 0.03298611636691009, 'n_estimators': 658, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.5871246763806427, 'colsample_bytree': 0.8580708414157834, 'gamma': 0.5259704740131659, 'lambda': 1.6722070828529463}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 15:57:57,997] Trial 113 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.3726244639574993, 'learning_rate': 0.03284474964247896, 'n_estimators': 633, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6097105132470187, 'colsample_bytree': 0.8733602966713896, 'gamma': 0.5243598342144129, 'lambda': 1.6790654359054065}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 15:58:18,227] Trial 114 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.4298442164158747, 'learning_rate': 0.02070064087019292, 'n_estimators': 612, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.6193530327172291, 'colsample_bytree': 0.8955306979045646, 'gamma': 0.5095391248177181, 'lambda': 1.7302343660530073}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 15:58:33,442] Trial 115 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.32496851521688797, 'learning_rate': 0.03398550187754268, 'n_estimators': 666, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.5887009830901326, 'colsample_bytree': 0.8584228833584193, 'gamma': 0.5396506227855846, 'lambda': 1.851454411743892}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 15:58:54,380] Trial 116 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.3787836545019586, 'learning_rate': 0.012446435433034808, 'n_estimators': 687, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5452405781070238, 'colsample_bytree': 0.8307537998236677, 'gamma': 0.5622153001750282, 'lambda': 1.5093962324662211}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 15:59:07,764] Trial 117 finished with value: 0.9213058419243987 and parameters: {'booster': 'gbtree', 'eta': 0.41125150264897126, 'learning_rate': 0.037655575673584435, 'n_estimators': 658, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.5715939227044601, 'colsample_bytree': 0.8410307336927162, 'gamma': 0.4071791128993965, 'lambda': 1.6670313948770572}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 16:02:57,460] Trial 118 finished with value: 0.9151202749140895 and parameters: {'booster': 'gbtree', 'eta': 0.3872505219360311, 'learning_rate': 0.006667393496702478, 'n_estimators': 596, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6046983041337016, 'colsample_bytree': 0.813798563949063, 'gamma': 0.50027681594592, 'lambda': 1.7529001637925692}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 16:03:10,074] Trial 119 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.45017976873039867, 'learning_rate': 0.04898538199790435, 'n_estimators': 706, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.5554799989970711, 'colsample_bytree': 0.8638182660307661, 'gamma': 0.5358252799415013, 'lambda': 1.5965931221867404}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 16:03:29,628] Trial 120 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.3641753769356712, 'learning_rate': 0.020451770048270767, 'n_estimators': 632, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.5933425929832387, 'colsample_bytree': 0.8286409782370806, 'gamma': 0.4594014099554273, 'lambda': 1.4332915436771625}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 16:03:43,352] Trial 121 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.33940830579683695, 'learning_rate': 0.04096558877550642, 'n_estimators': 654, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.5804710062882361, 'colsample_bytree': 0.8476323015098984, 'gamma': 0.49649915234399217, 'lambda': 1.6301815306194296}. Best is trial 111 with value: 0.9305841924398627.
[I 2024-06-06 16:03:58,608] Trial 122 finished with value: 0.9316151202749142 and parameters: {'booster': 'gbtree', 'eta': 0.3211721951605559, 'learning_rate': 0.03093338111029583, 'n_estimators': 679, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6340143449102265, 'colsample_bytree': 0.8729637099465908, 'gamma': 0.37848809641229664, 'lambda': 1.5896153170756488}. Best is trial 122 with value: 0.9316151202749142.
[I 2024-06-06 16:04:12,886] Trial 123 finished with value: 0.9309278350515465 and parameters: {'booster': 'gbtree', 'eta': 0.2878928960312678, 'learning_rate': 0.029681646518948734, 'n_estimators': 678, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6379964217402218, 'colsample_bytree': 0.8715563814687621, 'gamma': 0.38518871555699974, 'lambda': 1.5617781665618344}. Best is trial 122 with value: 0.9316151202749142.
[I 2024-06-06 16:04:24,753] Trial 124 finished with value: 0.9147766323024056 and parameters: {'booster': 'gbtree', 'eta': 0.31295076847732034, 'learning_rate': 0.03188499348080659, 'n_estimators': 674, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.6387225636927185, 'colsample_bytree': 0.8934266402090361, 'gamma': 0.3795160309110104, 'lambda': 1.5285333100625662}. Best is trial 122 with value: 0.9316151202749142.
[I 2024-06-06 16:04:43,609] Trial 125 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.2972828493306123, 'learning_rate': 0.02135406768130337, 'n_estimators': 708, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6271671323449797, 'colsample_bytree': 0.877371269638307, 'gamma': 0.351052477857792, 'lambda': 1.5720608624591916}. Best is trial 122 with value: 0.9316151202749142.
[I 2024-06-06 16:04:59,241] Trial 126 finished with value: 0.9195876288659796 and parameters: {'booster': 'gbtree', 'eta': 0.32063042030303507, 'learning_rate': 0.023781608988561066, 'n_estimators': 701, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6349079511539544, 'colsample_bytree': 0.8742558329388836, 'gamma': 0.35725564597360243, 'lambda': 1.4852034615763172}. Best is trial 122 with value: 0.9316151202749142.
[I 2024-06-06 16:05:13,759] Trial 127 finished with value: 0.9319587628865981 and parameters: {'booster': 'gbtree', 'eta': 0.29387275577824473, 'learning_rate': 0.03137990752066282, 'n_estimators': 683, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6221652206166824, 'colsample_bytree': 0.8797011756537677, 'gamma': 0.3447296743630426, 'lambda': 1.758105568924126}. Best is trial 127 with value: 0.9319587628865981.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:16] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:17] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:05:18] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 16:05:19,359] Trial 128 finished with value: 0.807216494845361 and parameters: {'booster': 'gblinear', 'eta': 0.3017674990968381, 'learning_rate': 0.0381243188637961, 'n_estimators': 717, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6474954243190432, 'colsample_bytree': 0.8926947514872452, 'gamma': 0.3325985470697907, 'lambda': 1.374510372531024}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:05:32,352] Trial 129 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.3582907286477796, 'learning_rate': 0.04522146824037169, 'n_estimators': 687, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6227664082004455, 'colsample_bytree': 0.8791471367956014, 'gamma': 0.3072486103074931, 'lambda': 1.7112387984097825}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:05:43,419] Trial 130 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.235755204622662, 'learning_rate': 0.07362544632646931, 'n_estimators': 713, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.6226499551308348, 'colsample_bytree': 0.8793999395901918, 'gamma': 0.29518708702143487, 'lambda': 1.577871327035685}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:05:56,194] Trial 131 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.2851747570271698, 'learning_rate': 0.048098247027042636, 'n_estimators': 689, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6619951609279778, 'colsample_bytree': 0.9059489101683156, 'gamma': 0.3844853195294621, 'lambda': 1.7049202490694304}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:06:08,488] Trial 132 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.3301125834421475, 'learning_rate': 0.032483915796674825, 'n_estimators': 678, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6158186537803921, 'colsample_bytree': 0.872476938875807, 'gamma': 0.44791426332663464, 'lambda': 1.82660694240573}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:06:23,076] Trial 133 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.3566197634985912, 'learning_rate': 0.04162339209496599, 'n_estimators': 612, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6286040523020081, 'colsample_bytree': 0.8674247616311868, 'gamma': 0.32286012862641467, 'lambda': 1.746865275131753}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:07:02,008] Trial 134 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.3576498634494223, 'learning_rate': 0.044047382089311145, 'n_estimators': 614, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6385749601783121, 'colsample_bytree': 0.8680217977642801, 'gamma': 0.3082630056871856, 'lambda': 1.7172910547447002}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:07:12,942] Trial 135 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.29181774452308956, 'learning_rate': 0.0617552899908933, 'n_estimators': 608, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6409768832662293, 'colsample_bytree': 0.8866821966558114, 'gamma': 0.30781683766369367, 'lambda': 1.7586692627559777}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:07:25,033] Trial 136 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.35710940857862006, 'learning_rate': 0.049009315141547494, 'n_estimators': 630, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.628044913630322, 'colsample_bytree': 0.9019494418306527, 'gamma': 0.33585067170210703, 'lambda': 1.8449336810423473}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:07:38,301] Trial 137 finished with value: 0.9319587628865981 and parameters: {'booster': 'gbtree', 'eta': 0.3578815345017399, 'learning_rate': 0.04099155851433818, 'n_estimators': 622, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6243980927118291, 'colsample_bytree': 0.8990994573825883, 'gamma': 0.2804664941987397, 'lambda': 1.9105811541898072}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:07:50,224] Trial 138 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.3590445982215091, 'learning_rate': 0.03895419007981101, 'n_estimators': 625, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6289552311998895, 'colsample_bytree': 0.901576118439959, 'gamma': 0.27922362267033585, 'lambda': 1.8697164473772294}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:08:02,001] Trial 139 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.3611385340761358, 'learning_rate': 0.03992126730971438, 'n_estimators': 619, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6298327121460168, 'colsample_bytree': 0.9238783603478762, 'gamma': 0.27424415758417314, 'lambda': 1.9037670955160466}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:08:10,866] Trial 140 finished with value: 0.9189003436426119 and parameters: {'booster': 'gbtree', 'eta': 0.35881166240362716, 'learning_rate': 0.040026716887445496, 'n_estimators': 614, 'max_depth': 2, 'min_child_weight': 1, 'subsample': 0.6264136970439037, 'colsample_bytree': 0.9236930385705117, 'gamma': 0.27182425448858616, 'lambda': 1.907060906145506}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:08:24,225] Trial 141 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.36266620244204095, 'learning_rate': 0.04111681746532634, 'n_estimators': 630, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6553920082618333, 'colsample_bytree': 0.9022568630001242, 'gamma': 0.2602344161503745, 'lambda': 1.8678118744898489}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:08:37,599] Trial 142 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.36217378504809555, 'learning_rate': 0.041725672822786296, 'n_estimators': 630, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6545847550327278, 'colsample_bytree': 0.9031002343439248, 'gamma': 0.26151478066865785, 'lambda': 1.88875166639793}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:15:46,890] Trial 143 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.4121588367465646, 'learning_rate': 0.05336012256551162, 'n_estimators': 595, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6594462319969067, 'colsample_bytree': 0.9048509488253357, 'gamma': 0.26890976873112715, 'lambda': 1.8545039271628065}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:20:22,896] Trial 144 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.35819998151045074, 'learning_rate': 0.041909392199075114, 'n_estimators': 628, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6511831975785832, 'colsample_bytree': 0.9219951809143152, 'gamma': 0.24044503710498244, 'lambda': 1.9097696914332163}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:20:36,736] Trial 145 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.32726914119529127, 'learning_rate': 0.041697921586241145, 'n_estimators': 626, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6495058710450318, 'colsample_bytree': 0.9173032788689552, 'gamma': 0.23871682888343715, 'lambda': 1.9116529798126523}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:20:49,006] Trial 146 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.35859117392133877, 'learning_rate': 0.06109050895592437, 'n_estimators': 620, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6477858030265573, 'colsample_bytree': 0.9394988438324641, 'gamma': 0.2370413489389445, 'lambda': 1.9203429156344067}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:21:00,209] Trial 147 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.2958079767920809, 'learning_rate': 0.041860999150370226, 'n_estimators': 602, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.6711831642979255, 'colsample_bytree': 0.9113770442026887, 'gamma': 0.22823141550684534, 'lambda': 1.9812663208809642}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:21:07,989] Trial 148 finished with value: 0.9206185567010311 and parameters: {'booster': 'gbtree', 'eta': 0.39677127219579383, 'learning_rate': 0.05536302423082527, 'n_estimators': 551, 'max_depth': 2, 'min_child_weight': 1, 'subsample': 0.6516239539159837, 'colsample_bytree': 0.9245042081935408, 'gamma': 0.3358223247857405, 'lambda': 1.8963741027304242}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:21:18,961] Trial 149 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.32488273551925667, 'learning_rate': 0.06986533658191557, 'n_estimators': 582, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6363902018058623, 'colsample_bytree': 0.8993987962143081, 'gamma': 0.23921361765646107, 'lambda': 1.8234130752746727}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:21:32,476] Trial 150 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.36327503637072633, 'learning_rate': 0.04200061180364228, 'n_estimators': 626, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6565697067258417, 'colsample_bytree': 0.9396765156049895, 'gamma': 0.21286804419385302, 'lambda': 1.9543701750666953}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:21:45,925] Trial 151 finished with value: 0.9309278350515465 and parameters: {'booster': 'gbtree', 'eta': 0.35408053665685973, 'learning_rate': 0.037583062868689614, 'n_estimators': 608, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6358221665616783, 'colsample_bytree': 0.9097311367373684, 'gamma': 0.2788317717570924, 'lambda': 1.876522706514445}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:21:56,951] Trial 152 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.34182671216932614, 'learning_rate': 0.05052801726904717, 'n_estimators': 607, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6337760811963821, 'colsample_bytree': 0.9084824586170591, 'gamma': 0.2738824864029229, 'lambda': 1.8765936135830348}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:22:10,640] Trial 153 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.2906066005673194, 'learning_rate': 0.03676981800923044, 'n_estimators': 587, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6434326508075752, 'colsample_bytree': 0.9178883396239451, 'gamma': 0.256064860749404, 'lambda': 1.9215333141836433}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:22:25,231] Trial 154 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.297109962706151, 'learning_rate': 0.038794720253469896, 'n_estimators': 588, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6387368264545693, 'colsample_bytree': 0.9155414898045227, 'gamma': 0.3244446171587334, 'lambda': 2.011171096639105}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:22:42,935] Trial 155 finished with value: 0.9309278350515465 and parameters: {'booster': 'gbtree', 'eta': 0.3203155447709368, 'learning_rate': 0.024967921346352548, 'n_estimators': 577, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.629036075882761, 'colsample_bytree': 0.9327289235514246, 'gamma': 0.2959782444247334, 'lambda': 1.9475603249343416}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:22:59,249] Trial 156 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.2842132622598932, 'learning_rate': 0.02549845386816682, 'n_estimators': 552, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.6684691132674431, 'colsample_bytree': 0.920673947291306, 'gamma': 0.290172791535638, 'lambda': 1.9303083376281984}. Best is trial 127 with value: 0.9319587628865981.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:22:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:22:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:22:59] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:23:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 16:23:03,927] Trial 157 finished with value: 0.8089347079037803 and parameters: {'booster': 'gblinear', 'eta': 0.3196295695403686, 'learning_rate': 0.014522080035448621, 'n_estimators': 576, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6451661731818987, 'colsample_bytree': 0.9300200428834319, 'gamma': 0.3134394226651674, 'lambda': 1.9311408874010692}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:23:17,709] Trial 158 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.3072264433234877, 'learning_rate': 0.024702852285860187, 'n_estimators': 561, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6286406766877487, 'colsample_bytree': 0.9343028586807971, 'gamma': 0.3521948905832938, 'lambda': 1.991771630575754}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:25:45,710] Trial 159 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.28567007850716164, 'learning_rate': 0.04683086305702695, 'n_estimators': 600, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6454451143873754, 'colsample_bytree': 0.9498336147820401, 'gamma': 0.2497768837724299, 'lambda': 1.8106275429513727}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:25:56,864] Trial 160 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.3336205330174705, 'learning_rate': 0.057085995762431854, 'n_estimators': 542, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6210339999790927, 'colsample_bytree': 0.9179256685433933, 'gamma': 0.29197474618256347, 'lambda': 1.801144621423358}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:27:37,295] Trial 161 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.3421417277742163, 'learning_rate': 0.037093803724054714, 'n_estimators': 584, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6299917372974433, 'colsample_bytree': 0.8918822342620201, 'gamma': 0.215265192474023, 'lambda': 1.892317308490441}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:27:58,862] Trial 162 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.42958842500872174, 'learning_rate': 0.028979300041946605, 'n_estimators': 608, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6654524056095584, 'colsample_bytree': 0.9103848052603297, 'gamma': 0.28322879898979225, 'lambda': 1.83840825203186}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:28:11,305] Trial 163 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.38876710502497813, 'learning_rate': 0.04420118969440776, 'n_estimators': 622, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6388247153422679, 'colsample_bytree': 0.9265392207796199, 'gamma': 0.3264225566596269, 'lambda': 1.9780710276648206}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:28:23,387] Trial 164 finished with value: 0.9312714776632304 and parameters: {'booster': 'gbtree', 'eta': 0.24976976595048112, 'learning_rate': 0.05182391518496164, 'n_estimators': 580, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6525984897194185, 'colsample_bytree': 0.8991708468488333, 'gamma': 0.3021413130468628, 'lambda': 1.754598117368332}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:36:37,261] Trial 165 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.24099363808243535, 'learning_rate': 0.0510870532715537, 'n_estimators': 533, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6795441448835223, 'colsample_bytree': 0.8914577930305089, 'gamma': 0.2555044885689157, 'lambda': 1.7756859330692842}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:36:48,183] Trial 166 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.2337236741127397, 'learning_rate': 0.06512362935625106, 'n_estimators': 516, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6784591363532354, 'colsample_bytree': 0.892460716555442, 'gamma': 0.2592397211331659, 'lambda': 1.763475322099636}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:36:58,336] Trial 167 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.24652491782901834, 'learning_rate': 0.06722655862716836, 'n_estimators': 509, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6798652224391473, 'colsample_bytree': 0.8898752275166208, 'gamma': 0.2544040271732651, 'lambda': 1.7690090281917483}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:37:07,724] Trial 168 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.2259353308414333, 'learning_rate': 0.07890311444475724, 'n_estimators': 501, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6790096649009554, 'colsample_bytree': 0.8877759501581263, 'gamma': 0.2556608936698495, 'lambda': 1.7525032351363188}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:37:19,254] Trial 169 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.24315544998697908, 'learning_rate': 0.058974803840506226, 'n_estimators': 535, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6877352690296097, 'colsample_bytree': 0.8918243984238775, 'gamma': 0.2082917950900981, 'lambda': 1.7851920865731015}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:37:28,467] Trial 170 finished with value: 0.9175257731958764 and parameters: {'booster': 'gbtree', 'eta': 0.24857018599971142, 'learning_rate': 0.06886940478093476, 'n_estimators': 521, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.6758099367648787, 'colsample_bytree': 0.9130349667992236, 'gamma': 0.19451524859462999, 'lambda': 1.7746576763949236}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:37:39,928] Trial 171 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.26596382891753584, 'learning_rate': 0.061586921432321695, 'n_estimators': 572, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6566020387766252, 'colsample_bytree': 0.8987430770392011, 'gamma': 0.25149290960253795, 'lambda': 1.836211357915945}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:37:50,513] Trial 172 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.18857266727823102, 'learning_rate': 0.05306214302659011, 'n_estimators': 524, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6624714612039067, 'colsample_bytree': 0.8823121261955346, 'gamma': 0.29731802426354936, 'lambda': 1.70652242389018}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:38:00,508] Trial 173 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.2173561178649375, 'learning_rate': 0.06486604406200984, 'n_estimators': 562, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6519564134710951, 'colsample_bytree': 0.8983280201957228, 'gamma': 0.339200478177227, 'lambda': 1.8106311426267048}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:38:12,118] Trial 174 finished with value: 0.9309278350515465 and parameters: {'booster': 'gbtree', 'eta': 0.2464402050592398, 'learning_rate': 0.05088340307543267, 'n_estimators': 533, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6697049287353716, 'colsample_bytree': 0.9174327064135241, 'gamma': 0.3042729069621784, 'lambda': 1.9338751740925209}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:38:23,382] Trial 175 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.2512619573625532, 'learning_rate': 0.05275606774223657, 'n_estimators': 535, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6847770152753733, 'colsample_bytree': 0.9335274863284969, 'gamma': 0.3060073198356494, 'lambda': 1.940076047233522}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:38:33,230] Trial 176 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.23503958843579953, 'learning_rate': 0.08393946225751629, 'n_estimators': 504, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6731869332133282, 'colsample_bytree': 0.9143356506963526, 'gamma': 0.250661329974518, 'lambda': 2.009293480145778}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:38:47,488] Trial 177 finished with value: 0.9312714776632304 and parameters: {'booster': 'gbtree', 'eta': 0.26551162986800875, 'learning_rate': 0.033966823485472634, 'n_estimators': 517, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6684969581177173, 'colsample_bytree': 0.9415805104609163, 'gamma': 0.22957995169269546, 'lambda': 1.9508047096677201}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:39:01,752] Trial 178 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.2673336227618363, 'learning_rate': 0.03477803598479891, 'n_estimators': 546, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.7013728819501878, 'colsample_bytree': 0.9518159396776511, 'gamma': 0.1902619972978008, 'lambda': 2.028629388439107}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:39:14,044] Trial 179 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.2820459697957012, 'learning_rate': 0.02953155893563853, 'n_estimators': 523, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6682433585669872, 'colsample_bytree': 0.9428029693052292, 'gamma': 0.22870863816475584, 'lambda': 1.9399042552527805}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:39:32,729] Trial 180 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.22849480698443092, 'learning_rate': 0.020913082641351124, 'n_estimators': 566, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6481077722606616, 'colsample_bytree': 0.9334405064370705, 'gamma': 0.294789337386718, 'lambda': 1.972630197134825}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:39:44,969] Trial 181 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.21060102706110936, 'learning_rate': 0.045291400302568424, 'n_estimators': 512, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6620271056102001, 'colsample_bytree': 0.8866172396370053, 'gamma': 0.2627267125496251, 'lambda': 1.887156700680901}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:39:57,291] Trial 182 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.2517612344117846, 'learning_rate': 0.03510080350364877, 'n_estimators': 528, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6976337036153204, 'colsample_bytree': 0.92055064868092, 'gamma': 0.23354362291263006, 'lambda': 1.744168113625195}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:40:06,581] Trial 183 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.29315853117444857, 'learning_rate': 0.07536345235239957, 'n_estimators': 512, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6805260219664244, 'colsample_bytree': 0.9645337805269455, 'gamma': 0.2784938943710397, 'lambda': 1.6915417385346276}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:40:17,972] Trial 184 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.1987111762463762, 'learning_rate': 0.04953251647121417, 'n_estimators': 543, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6901618940519988, 'colsample_bytree': 0.8779495962927071, 'gamma': 0.31859203138975434, 'lambda': 2.1233069372275986}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:40:29,898] Trial 185 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.3097840008874718, 'learning_rate': 0.024517467696134443, 'n_estimators': 500, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6533867159806469, 'colsample_bytree': 0.9046951715414279, 'gamma': 0.350168860957516, 'lambda': 1.5711958123064917}. Best is trial 127 with value: 0.9319587628865981.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:29] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:31] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:32] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:40:33] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 16:40:34,194] Trial 186 finished with value: 0.8061855670103095 and parameters: {'booster': 'gblinear', 'eta': 0.257126265622426, 'learning_rate': 0.06684052315209446, 'n_estimators': 550, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6428008730686335, 'colsample_bytree': 0.9490035593820312, 'gamma': 0.36895186207128905, 'lambda': 1.9047061175660909}. Best is trial 127 with value: 0.9319587628865981.
[I 2024-06-06 16:40:42,203] Trial 187 finished with value: 0.9323024054982819 and parameters: {'booster': 'gbtree', 'eta': 0.2676847393106996, 'learning_rate': 0.10850551030802212, 'n_estimators': 533, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.7122929537139789, 'colsample_bytree': 0.8940980841288361, 'gamma': 0.2594468463443549, 'lambda': 1.7848112850108784}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:40:55,842] Trial 188 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.282505152884589, 'learning_rate': 0.030097910475866612, 'n_estimators': 585, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.7157651018059206, 'colsample_bytree': 0.9085776650084755, 'gamma': 0.29766266376847256, 'lambda': 1.8463568117711093}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:41:05,388] Trial 189 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.30917002984228176, 'learning_rate': 0.10123307238646077, 'n_estimators': 572, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6156908198289872, 'colsample_bytree': 0.9285431474023119, 'gamma': 0.2783560449580257, 'lambda': 1.9410896247136764}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:41:17,598] Trial 190 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.22328816962425366, 'learning_rate': 0.035286584417943676, 'n_estimators': 534, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.664024662912023, 'colsample_bytree': 0.918051435576969, 'gamma': 0.31181792100974176, 'lambda': 1.8075050371831731}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:41:25,870] Trial 191 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.28754008484555466, 'learning_rate': 0.11694643928666318, 'n_estimators': 522, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6772898287790607, 'colsample_bytree': 0.8920341376820211, 'gamma': 0.24819994577492152, 'lambda': 1.7348100617947158}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:41:35,601] Trial 192 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.2628868125013166, 'learning_rate': 0.08741511416237657, 'n_estimators': 554, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.643775758369881, 'colsample_bytree': 0.8753585666403622, 'gamma': 0.2590726515844334, 'lambda': 1.7653228484461627}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:41:47,054] Trial 193 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.23407073916798596, 'learning_rate': 0.046231795708874424, 'n_estimators': 515, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6929415215863248, 'colsample_bytree': 0.8939071311617239, 'gamma': 0.21761081515818748, 'lambda': 1.6756366637212305}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:41:58,968] Trial 194 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.2684742924093616, 'learning_rate': 0.05540044470529679, 'n_estimators': 532, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6554571158406975, 'colsample_bytree': 0.8856394885778451, 'gamma': 0.2332331260424085, 'lambda': 1.8791207073512366}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:42:07,166] Trial 195 finished with value: 0.9257731958762888 and parameters: {'booster': 'gbtree', 'eta': 0.27346884117482656, 'learning_rate': 0.10712658112444196, 'n_estimators': 534, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6377878523848719, 'colsample_bytree': 0.8781662310882791, 'gamma': 0.2723906774113354, 'lambda': 1.8781970567066772}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:42:20,273] Trial 196 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.310727392657457, 'learning_rate': 0.05680827252765161, 'n_estimators': 561, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6542478323504852, 'colsample_bytree': 0.8681454203162028, 'gamma': 0.23800236788761978, 'lambda': 1.9729844928772535}. Best is trial 187 with value: 0.9323024054982819.
[I 2024-06-06 16:42:34,247] Trial 197 finished with value: 0.9333333333333335 and parameters: {'booster': 'gbtree', 'eta': 0.3180223149241086, 'learning_rate': 0.05762271040015525, 'n_estimators': 583, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6536020635934753, 'colsample_bytree': 0.868674796270652, 'gamma': 0.18847462928688213, 'lambda': 1.9992308272971038}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:42:48,421] Trial 198 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.32257564851935133, 'learning_rate': 0.05690225495338115, 'n_estimators': 591, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.655011157967604, 'colsample_bytree': 0.8635589039057677, 'gamma': 0.19209171666108704, 'lambda': 2.0529549885026928}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:42:58,138] Trial 199 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.3098983128448865, 'learning_rate': 0.13035783751737723, 'n_estimators': 563, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6459093016849304, 'colsample_bytree': 0.8693069193697331, 'gamma': 0.17646170079925622, 'lambda': 1.9874471841831443}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:43:13,427] Trial 200 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.3256204054477992, 'learning_rate': 0.04498202042745498, 'n_estimators': 583, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6193517736189951, 'colsample_bytree': 0.9421638983612893, 'gamma': 0.22722128411129566, 'lambda': 2.092932643399931}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:43:27,060] Trial 201 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.2977267319369755, 'learning_rate': 0.050435073374314944, 'n_estimators': 597, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6658033643298001, 'colsample_bytree': 0.8820725731932318, 'gamma': 0.23786019279836268, 'lambda': 1.9719815990057679}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:43:37,416] Trial 202 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.32907284272830484, 'learning_rate': 0.05786236064353198, 'n_estimators': 551, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6544980272536428, 'colsample_bytree': 0.909123032868833, 'gamma': 0.3698239609156115, 'lambda': 2.021895944460043}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:43:51,402] Trial 203 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.2751442189098875, 'learning_rate': 0.037006803632494964, 'n_estimators': 573, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6371085264799711, 'colsample_bytree': 0.8691030449983639, 'gamma': 0.21000962542518598, 'lambda': 1.9337851198207563}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:44:05,389] Trial 204 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.3006904155890939, 'learning_rate': 0.052939958843526605, 'n_estimators': 639, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6484092768684422, 'colsample_bytree': 0.9017048267993671, 'gamma': 0.29516547527255255, 'lambda': 1.9124888303504797}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:44:16,652] Trial 205 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.3400126079174221, 'learning_rate': 0.09403803183280027, 'n_estimators': 600, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6365956776217113, 'colsample_bytree': 0.9233902000244925, 'gamma': 0.15936735198114046, 'lambda': 1.882035905060909}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:44:28,686] Trial 206 finished with value: 0.9264604810996565 and parameters: {'booster': 'gbtree', 'eta': 0.310370580479267, 'learning_rate': 0.04280297713998221, 'n_estimators': 664, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6675060930264562, 'colsample_bytree': 0.8836699743563583, 'gamma': 0.34488046126338984, 'lambda': 1.8438034630320668}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:44:47,234] Trial 207 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.5442838425432914, 'learning_rate': 0.028875760183811522, 'n_estimators': 539, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6600184935674478, 'colsample_bytree': 0.9843382986429837, 'gamma': 0.31725884014113503, 'lambda': 1.9776971498436038}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:45:06,555] Trial 208 finished with value: 0.9254295532646049 and parameters: {'booster': 'gbtree', 'eta': 0.28424980442573833, 'learning_rate': 0.016114904546369754, 'n_estimators': 563, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.731010940200943, 'colsample_bytree': 0.8690735266036606, 'gamma': 0.22697979078483999, 'lambda': 2.040124192632949}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:45:20,248] Trial 209 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.2643236637570188, 'learning_rate': 0.034867380697024025, 'n_estimators': 581, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6084505449037318, 'colsample_bytree': 0.9170302742804104, 'gamma': 0.2796703217021883, 'lambda': 1.9091918619584063}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:45:34,164] Trial 210 finished with value: 0.9312714776632304 and parameters: {'booster': 'gbtree', 'eta': 0.3279176118924012, 'learning_rate': 0.04203289134303323, 'n_estimators': 610, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6203405301440792, 'colsample_bytree': 0.9622670600285854, 'gamma': 0.2417234196322648, 'lambda': 1.6032610254677677}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:45:48,391] Trial 211 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.33472997415806016, 'learning_rate': 0.04321005231253236, 'n_estimators': 646, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6185475710152291, 'colsample_bytree': 0.9635107046034015, 'gamma': 0.2410871510710556, 'lambda': 1.5468707264463275}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:45:59,232] Trial 212 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.31647898145978703, 'learning_rate': 0.04953107195480827, 'n_estimators': 614, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6333800927676918, 'colsample_bytree': 0.9546275792397103, 'gamma': 0.3901925045316159, 'lambda': 1.6097207138480034}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:46:14,577] Trial 213 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.29625502354419336, 'learning_rate': 0.037974341948267716, 'n_estimators': 602, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6472690988642968, 'colsample_bytree': 0.9322769521212287, 'gamma': 0.26538260758478255, 'lambda': 1.625831744311119}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:46:22,844] Trial 214 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.34476730762556046, 'learning_rate': 0.1452588257272308, 'n_estimators': 631, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6253317213982329, 'colsample_bytree': 0.9792103306454454, 'gamma': 0.36065487270347985, 'lambda': 1.4913286159881025}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:47:21,443] Trial 215 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.32492367138792544, 'learning_rate': 0.060214413206456194, 'n_estimators': 557, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6555363676971369, 'colsample_bytree': 0.8990749403511851, 'gamma': 0.2845458238350608, 'lambda': 1.9579709064760609}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:47:40,219] Trial 216 finished with value: 0.9319587628865981 and parameters: {'booster': 'gbtree', 'eta': 0.2778020877554934, 'learning_rate': 0.02295538498705333, 'n_estimators': 664, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6040427561723221, 'colsample_bytree': 0.9424657568072314, 'gamma': 0.242407969751109, 'lambda': 1.83323256095677}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:47:50,610] Trial 217 finished with value: 0.9151202749140895 and parameters: {'booster': 'gbtree', 'eta': 0.2801319832916581, 'learning_rate': 0.15557061110616216, 'n_estimators': 663, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.5994937885844672, 'colsample_bytree': 0.9424797307545761, 'gamma': 0.2072345337938085, 'lambda': 1.8582410118320254}. Best is trial 197 with value: 0.9333333333333335.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:50] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:51] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:51] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:51] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:52] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:53] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:54] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:47:55] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 16:47:55,783] Trial 218 finished with value: 0.8061855670103095 and parameters: {'booster': 'gblinear', 'eta': 0.3013356694441381, 'learning_rate': 0.02295124287004883, 'n_estimators': 649, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.6082430346552222, 'colsample_bytree': 0.9717796434505148, 'gamma': 0.242308821594249, 'lambda': 1.819142232195008}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:48:13,788] Trial 219 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.375651303730419, 'learning_rate': 0.028990157126938407, 'n_estimators': 638, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6192566667198603, 'colsample_bytree': 0.9498733617180999, 'gamma': 0.32539304527072893, 'lambda': 2.0111632676422815}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:48:27,003] Trial 220 finished with value: 0.9147766323024057 and parameters: {'booster': 'gbtree', 'eta': 0.26601072163837686, 'learning_rate': 0.011662010843494844, 'n_estimators': 693, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6391778076047233, 'colsample_bytree': 0.9619604482512747, 'gamma': 0.16781056974197434, 'lambda': 2.0714851983656746}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:48:36,338] Trial 221 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.25281367556761913, 'learning_rate': 0.12322668556147387, 'n_estimators': 614, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.627868789091288, 'colsample_bytree': 0.9318578371385301, 'gamma': 0.2245379631510981, 'lambda': 1.9122196383126426}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:48:49,806] Trial 222 finished with value: 0.9312714776632304 and parameters: {'booster': 'gbtree', 'eta': 0.28646793528193837, 'learning_rate': 0.042077280275711844, 'n_estimators': 581, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6709373081004202, 'colsample_bytree': 0.9092799318281218, 'gamma': 0.2555377085017064, 'lambda': 1.8254903938127423}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:49:02,865] Trial 223 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.3213084824207309, 'learning_rate': 0.03249987612768757, 'n_estimators': 589, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6442769063760697, 'colsample_bytree': 0.9197678413532707, 'gamma': 0.30240752893128525, 'lambda': 1.8647988204850299}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:49:16,755] Trial 224 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.286594620459821, 'learning_rate': 0.03971101732530859, 'n_estimators': 578, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6562691071224886, 'colsample_bytree': 0.9104722429906632, 'gamma': 0.24134186908779956, 'lambda': 1.9364304801691012}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:50:38,149] Trial 225 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.3402389884070055, 'learning_rate': 0.027785890318673425, 'n_estimators': 673, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6713671399838067, 'colsample_bytree': 0.9376025792627805, 'gamma': 0.2626695896573168, 'lambda': 1.5802654595088803}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:50:47,895] Trial 226 finished with value: 0.9130584192439865 and parameters: {'booster': 'gbtree', 'eta': 0.344227068699469, 'learning_rate': 0.02167593885026525, 'n_estimators': 677, 'max_depth': 2, 'min_child_weight': 1, 'subsample': 0.6675213322082028, 'colsample_bytree': 0.9443996492125304, 'gamma': 0.2794153875035879, 'lambda': 1.5782560630136409}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:51:03,657] Trial 227 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.3423743103337647, 'learning_rate': 0.03013342678422517, 'n_estimators': 663, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6022404123693968, 'colsample_bytree': 0.9934724056949611, 'gamma': 0.35029585752833164, 'lambda': 1.530203874687842}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:51:24,334] Trial 228 finished with value: 0.9309278350515465 and parameters: {'booster': 'gbtree', 'eta': 0.31476810572782377, 'learning_rate': 0.02637258121983045, 'n_estimators': 708, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6723352980764487, 'colsample_bytree': 0.9320386332083519, 'gamma': 0.20360056329813803, 'lambda': 1.5780526787609297}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:51:43,058] Trial 229 finished with value: 0.9223367697594502 and parameters: {'booster': 'gbtree', 'eta': 0.3112674050456812, 'learning_rate': 0.01573213268886036, 'n_estimators': 700, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6689653702591598, 'colsample_bytree': 0.9622535781453514, 'gamma': 0.21951721243816208, 'lambda': 1.5901718327271597}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:52:06,128] Trial 230 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.314655970729116, 'learning_rate': 0.02503195467503215, 'n_estimators': 713, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6873161839782033, 'colsample_bytree': 0.9385837073170702, 'gamma': 0.18673466022468244, 'lambda': 1.4771126137913952}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:52:22,013] Trial 231 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.3753648770720092, 'learning_rate': 0.04473025248999059, 'n_estimators': 670, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6607371540432223, 'colsample_bytree': 0.9308128061716171, 'gamma': 0.1961131924805366, 'lambda': 1.6745271697268895}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:52:42,884] Trial 232 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.3774623070764131, 'learning_rate': 0.02616373984028945, 'n_estimators': 677, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6606258778363554, 'colsample_bytree': 0.9313774655807872, 'gamma': 0.16043145312781779, 'lambda': 1.654057144517399}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:58:47,636] Trial 233 finished with value: 0.9333333333333335 and parameters: {'booster': 'gbtree', 'eta': 0.8726517366626871, 'learning_rate': 0.04700297152876652, 'n_estimators': 693, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6719235004243118, 'colsample_bytree': 0.9455484832710929, 'gamma': 0.14565977822140666, 'lambda': 1.6806173422230606}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:59:03,902] Trial 234 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.9424638399615708, 'learning_rate': 0.047524474858790036, 'n_estimators': 723, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6739030218171245, 'colsample_bytree': 0.9580781913587426, 'gamma': 0.19685888768388932, 'lambda': 1.6592199218896364}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:59:29,912] Trial 235 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.7245140034552512, 'learning_rate': 0.01997419149736065, 'n_estimators': 692, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6890570446826885, 'colsample_bytree': 0.949002196212442, 'gamma': 0.17259222731125118, 'lambda': 1.6956767580162486}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:59:39,902] Trial 236 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.8191135900682907, 'learning_rate': 0.14167950512272914, 'n_estimators': 709, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6715202199448042, 'colsample_bytree': 0.9442672506949868, 'gamma': 0.2075736534016044, 'lambda': 1.612978425233484}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 16:59:49,743] Trial 237 finished with value: 0.9268041237113404 and parameters: {'booster': 'gbtree', 'eta': 0.6567806284957307, 'learning_rate': 0.16274987670111984, 'n_estimators': 706, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.7046235396853294, 'colsample_bytree': 0.9408288073776905, 'gamma': 0.15265597498231326, 'lambda': 1.59636356220577}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:00:00,949] Trial 238 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.4719219052639, 'learning_rate': 0.13427414803579718, 'n_estimators': 731, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6747046388289908, 'colsample_bytree': 0.9515709720110357, 'gamma': 0.1341215418623842, 'lambda': 1.528082597650968}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:00:10,925] Trial 239 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.892838342105088, 'learning_rate': 0.1302920597828219, 'n_estimators': 682, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6946709860296445, 'colsample_bytree': 0.9703619151270312, 'gamma': 0.21182477204344166, 'lambda': 1.628290091248365}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:00:21,715] Trial 240 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.8526032440603165, 'learning_rate': 0.11537783400501864, 'n_estimators': 700, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6680403637321932, 'colsample_bytree': 0.9343954679931542, 'gamma': 0.19883427134537965, 'lambda': 1.5654143818581019}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:00:32,202] Trial 241 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.5200110682900361, 'learning_rate': 0.1797666510785017, 'n_estimators': 771, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6758412622269014, 'colsample_bytree': 0.9533253179650905, 'gamma': 0.1501500483714708, 'lambda': 1.5293662097605536}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:00:45,626] Trial 242 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.46345421065861664, 'learning_rate': 0.09514566257263388, 'n_estimators': 753, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6720562341050609, 'colsample_bytree': 0.9460497582344354, 'gamma': 0.10882804301611072, 'lambda': 1.5311511987223385}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:00:54,866] Trial 243 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.7749040109679787, 'learning_rate': 0.14000396964348225, 'n_estimators': 733, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6819290437478107, 'colsample_bytree': 0.9568490983146524, 'gamma': 0.3938506463469843, 'lambda': 1.4434976582538457}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:01:05,596] Trial 244 finished with value: 0.9312714776632304 and parameters: {'booster': 'gbtree', 'eta': 0.6137147313686142, 'learning_rate': 0.13873104168856154, 'n_estimators': 710, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6651711514299882, 'colsample_bytree': 0.9301727644710736, 'gamma': 0.11506077438967234, 'lambda': 1.6094548008640293}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:05:23,316] Trial 245 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.6212499951988626, 'learning_rate': 0.1494126587127942, 'n_estimators': 714, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6616060145993188, 'colsample_bytree': 0.9267739548874357, 'gamma': 0.22356514384303672, 'lambda': 1.6033719200574386}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:05:33,378] Trial 246 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.7951594709339731, 'learning_rate': 0.12637057187610673, 'n_estimators': 672, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6136195363103023, 'colsample_bytree': 0.9361038915966178, 'gamma': 0.19566808940411543, 'lambda': 1.6536944135084957}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:05:42,695] Trial 247 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.5874707744362075, 'learning_rate': 0.14243327049796498, 'n_estimators': 693, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6592491549235034, 'colsample_bytree': 0.9262718924018674, 'gamma': 0.23383235204147976, 'lambda': 1.7003879742273873}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:05:52,016] Trial 248 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.971143368005391, 'learning_rate': 0.15565692625913283, 'n_estimators': 666, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6497790359022461, 'colsample_bytree': 0.9406376270564549, 'gamma': 0.18290896492773628, 'lambda': 1.6005915303130205}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:08:26,400] Trial 249 finished with value: 0.9243986254295534 and parameters: {'booster': 'gbtree', 'eta': 0.27459477367838336, 'learning_rate': 0.13668285777027706, 'n_estimators': 791, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7106569778337508, 'colsample_bytree': 0.9117764965604054, 'gamma': 0.21208605715596376, 'lambda': 1.6553949346572454}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:08:37,427] Trial 250 finished with value: 0.9285223367697596 and parameters: {'booster': 'gbtree', 'eta': 0.3032767231570634, 'learning_rate': 0.14166690825158007, 'n_estimators': 656, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6294696082828037, 'colsample_bytree': 0.8780101422193242, 'gamma': 0.10792633812356975, 'lambda': 1.5698158487706724}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:08:49,478] Trial 251 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.29452054848339615, 'learning_rate': 0.10785296822601778, 'n_estimators': 888, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6844565590702064, 'colsample_bytree': 0.9284657662114932, 'gamma': 0.2590021344603272, 'lambda': 1.6820169681553052}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:08:59,257] Trial 252 finished with value: 0.9250859106529211 and parameters: {'booster': 'gbtree', 'eta': 0.6756364864899846, 'learning_rate': 0.11211640483675617, 'n_estimators': 715, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6676732899443772, 'colsample_bytree': 0.9713989441765559, 'gamma': 0.2874302723803783, 'lambda': 1.3670757827697546}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:09:10,312] Trial 253 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.3316430472975102, 'learning_rate': 0.080422249530962, 'n_estimators': 686, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6228828527444067, 'colsample_bytree': 0.9062272121937953, 'gamma': 0.33945235120616857, 'lambda': 1.728167277448367}. Best is trial 197 with value: 0.9333333333333335.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:10] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:11] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:12] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:13] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:09:15] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 17:09:15,426] Trial 254 finished with value: 0.8116838487972511 and parameters: {'booster': 'gblinear', 'eta': 0.8839931280850236, 'learning_rate': 0.03317620298142533, 'n_estimators': 647, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.6515753460854473, 'colsample_bytree': 0.8859136830996496, 'gamma': 0.23867323507008942, 'lambda': 0.5402868019419071}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:19:57,065] Trial 255 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.26917371359819775, 'learning_rate': 0.05527736436126875, 'n_estimators': 543, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7252811760593579, 'colsample_bytree': 0.9400129800673449, 'gamma': 0.38287615931047125, 'lambda': 1.6294315818429541}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:20:08,125] Trial 256 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.3270238103148785, 'learning_rate': 0.11884946882531738, 'n_estimators': 675, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6344485376356469, 'colsample_bytree': 0.9196987416001644, 'gamma': 0.1990042339886243, 'lambda': 1.807707460043761}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:20:26,664] Trial 257 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.48568916348951235, 'learning_rate': 0.02916399201712582, 'n_estimators': 1002, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7672208951462466, 'colsample_bytree': 0.8600959606210291, 'gamma': 0.3646797554903757, 'lambda': 1.4895761363110445}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:20:40,106] Trial 258 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.4444183590026818, 'learning_rate': 0.07509753571081004, 'n_estimators': 934, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.7446937226820988, 'colsample_bytree': 0.9307126604358049, 'gamma': 0.17874752090062795, 'lambda': 1.5784584499039664}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:21:06,234] Trial 259 finished with value: 0.9144329896907218 and parameters: {'booster': 'gbtree', 'eta': 0.510925720645963, 'learning_rate': 0.007704735186177557, 'n_estimators': 748, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6922177696014485, 'colsample_bytree': 0.5365246847420037, 'gamma': 0.2741679492537637, 'lambda': 2.9421321024144214}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:21:15,370] Trial 260 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.7325540949322976, 'learning_rate': 0.14816469497585158, 'n_estimators': 710, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.65826171651645, 'colsample_bytree': 0.8969185266708265, 'gamma': 0.30748909436239136, 'lambda': 1.713348612605232}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:21:24,298] Trial 261 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.25731474466021814, 'learning_rate': 0.16928121160882684, 'n_estimators': 656, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.5995495369998827, 'colsample_bytree': 0.8775473382374568, 'gamma': 0.21810022524437592, 'lambda': 1.6211131547405209}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:21:33,605] Trial 262 finished with value: 0.9312714776632304 and parameters: {'booster': 'gbtree', 'eta': 0.2945513619356223, 'learning_rate': 0.08906565035244049, 'n_estimators': 567, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6415985913251094, 'colsample_bytree': 0.9121201471871223, 'gamma': 0.253637569206484, 'lambda': 1.776645496109621}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:21:42,939] Trial 263 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.29184697037680063, 'learning_rate': 0.08890545914174094, 'n_estimators': 568, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6415738034071307, 'colsample_bytree': 0.9112570756783203, 'gamma': 0.2585386197158074, 'lambda': 1.7962136053157942}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:21:52,778] Trial 264 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.31095560291762253, 'learning_rate': 0.07123287375795137, 'n_estimators': 550, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6148515828640332, 'colsample_bytree': 0.9007926855641235, 'gamma': 0.2886224969607715, 'lambda': 1.7548728297606593}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:22:04,994] Trial 265 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.5540925942742227, 'learning_rate': 0.03702199510602036, 'n_estimators': 528, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6307884686965859, 'colsample_bytree': 0.8876810441444263, 'gamma': 0.24833257755964483, 'lambda': 1.8587908167340703}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:22:12,744] Trial 266 finished with value: 0.925429553264605 and parameters: {'booster': 'gbtree', 'eta': 0.6012103683430955, 'learning_rate': 0.10873499479887429, 'n_estimators': 569, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.647415195584706, 'colsample_bytree': 0.922031577810875, 'gamma': 0.4022790400933756, 'lambda': 1.814393653062092}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:22:22,067] Trial 267 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.2786397306444686, 'learning_rate': 0.09733660515380298, 'n_estimators': 599, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6353072509148341, 'colsample_bytree': 0.8702771138486428, 'gamma': 0.3209628243641608, 'lambda': 1.6885437949933424}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:22:33,330] Trial 268 finished with value: 0.9305841924398627 and parameters: {'booster': 'gbtree', 'eta': 0.245671827106558, 'learning_rate': 0.05262319352673227, 'n_estimators': 557, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6223636722698926, 'colsample_bytree': 0.9110896314161776, 'gamma': 0.2713673813050306, 'lambda': 1.9812750967403772}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:22:44,628] Trial 269 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.3952474494864524, 'learning_rate': 0.06038788257972917, 'n_estimators': 645, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.7027762141864048, 'colsample_bytree': 0.7482896904904938, 'gamma': 0.237286152999443, 'lambda': 1.7429239495590882}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:23:00,635] Trial 270 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.721575335593535, 'learning_rate': 0.10221209631065056, 'n_estimators': 1334, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.611771950514121, 'colsample_bytree': 0.7243920807281701, 'gamma': 0.297881810841658, 'lambda': 1.8494062249615726}. Best is trial 197 with value: 0.9333333333333335.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:00] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:01] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:02] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:03] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:23:04] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 17:23:04,995] Trial 271 finished with value: 0.8065292096219933 and parameters: {'booster': 'gblinear', 'eta': 0.3354215263250889, 'learning_rate': 0.04510682038305546, 'n_estimators': 544, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6615804842788027, 'colsample_bytree': 0.8951686990747887, 'gamma': 0.3717935241901814, 'lambda': 1.7986274053449893}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:23:16,042] Trial 272 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.3067265912665411, 'learning_rate': 0.09023835306148514, 'n_estimators': 577, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6436597033957999, 'colsample_bytree': 0.9210571427239111, 'gamma': 0.12756735470256525, 'lambda': 2.1388730611340034}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:23:29,571] Trial 273 finished with value: 0.9168384879725088 and parameters: {'booster': 'gbtree', 'eta': 0.2862780699176008, 'learning_rate': 0.02344562013048781, 'n_estimators': 601, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.5947684989545852, 'colsample_bytree': 0.8581040813575082, 'gamma': 0.2652306864374249, 'lambda': 1.5428429682005778}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:23:41,273] Trial 274 finished with value: 0.929896907216495 and parameters: {'booster': 'gbtree', 'eta': 0.3205628342206837, 'learning_rate': 0.0348951785149688, 'n_estimators': 531, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6549402552845254, 'colsample_bytree': 0.8811995817542129, 'gamma': 0.3456764103864168, 'lambda': 1.664863039372356}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:23:51,782] Trial 275 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.25995758311500083, 'learning_rate': 0.1889262756317173, 'n_estimators': 910, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6381134148901092, 'colsample_bytree': 0.9048674408708365, 'gamma': 0.2277461656112681, 'lambda': 1.9467246034820795}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:24:04,477] Trial 276 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.3431027593782872, 'learning_rate': 0.04122846848127001, 'n_estimators': 517, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8152376366549776, 'colsample_bytree': 0.6876249003820021, 'gamma': 0.24732004051475778, 'lambda': 1.4840907659922526}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:24:15,875] Trial 277 finished with value: 0.9219931271477665 and parameters: {'booster': 'gbtree', 'eta': 0.4206059794141108, 'learning_rate': 0.08171777506465051, 'n_estimators': 668, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8753994330695183, 'colsample_bytree': 0.9817916791051639, 'gamma': 0.28391009662343913, 'lambda': 2.022166330531792}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:24:33,349] Trial 278 finished with value: 0.9247422680412373 and parameters: {'booster': 'gbtree', 'eta': 0.18311191516645536, 'learning_rate': 0.017113743295957294, 'n_estimators': 581, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7163453168211397, 'colsample_bytree': 0.5594816961570703, 'gamma': 0.3267411426209955, 'lambda': 2.9974989870282083}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:24:48,999] Trial 279 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.21228033101671243, 'learning_rate': 0.0303420533981089, 'n_estimators': 854, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6234421352285872, 'colsample_bytree': 0.9348741587613131, 'gamma': 0.25987371686693744, 'lambda': 1.7580097693045247}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:25:01,417] Trial 280 finished with value: 0.9316151202749142 and parameters: {'booster': 'gbtree', 'eta': 0.6287143595908269, 'learning_rate': 0.05044571613448647, 'n_estimators': 628, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6820467074789792, 'colsample_bytree': 0.7701791142565223, 'gamma': 0.3023831704773525, 'lambda': 1.8405086521684957}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:25:16,197] Trial 281 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.2757251813814883, 'learning_rate': 0.06490243210171484, 'n_estimators': 1030, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6826185263412194, 'colsample_bytree': 0.867573694290683, 'gamma': 0.3136795493268498, 'lambda': 1.8730850459295714}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:25:32,388] Trial 282 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.6530366534413268, 'learning_rate': 0.051444529933832334, 'n_estimators': 1113, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.672492621344571, 'colsample_bytree': 0.7757798012639044, 'gamma': 0.3016177841153733, 'lambda': 1.847018058808551}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:25:43,659] Trial 283 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.5839792976028291, 'learning_rate': 0.05850788456565802, 'n_estimators': 624, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.605665496967117, 'colsample_bytree': 0.782299445239458, 'gamma': 0.41348174173691965, 'lambda': 1.9045819516900164}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:26:07,327] Trial 284 finished with value: 0.9281786941580757 and parameters: {'booster': 'gbtree', 'eta': 0.5451696687795983, 'learning_rate': 0.02580096122407118, 'n_estimators': 1193, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6835307460406155, 'colsample_bytree': 0.7645139620414216, 'gamma': 0.3299496101413099, 'lambda': 1.7926836872644893}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:26:20,279] Trial 285 finished with value: 0.9292096219931273 and parameters: {'booster': 'gbtree', 'eta': 0.7020370022812419, 'learning_rate': 0.04893461341547537, 'n_estimators': 636, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6973988651599418, 'colsample_bytree': 0.8853817721732307, 'gamma': 0.27763121270691987, 'lambda': 1.821273357014155}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:26:38,496] Trial 286 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.5190031271086544, 'learning_rate': 0.03586496679068252, 'n_estimators': 1240, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6498049614632613, 'colsample_bytree': 0.873077718471788, 'gamma': 0.5125300278866358, 'lambda': 1.9466075706278434}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:26:52,502] Trial 287 finished with value: 0.9295532646048111 and parameters: {'booster': 'gbtree', 'eta': 0.7535503347989491, 'learning_rate': 0.04005243469670906, 'n_estimators': 610, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6644101609333325, 'colsample_bytree': 0.745254207590527, 'gamma': 0.2946994941800287, 'lambda': 1.9900144540561664}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:27:04,438] Trial 288 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.3054076233870259, 'learning_rate': 0.05614728330801514, 'n_estimators': 594, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.629972754199718, 'colsample_bytree': 0.7910700230204957, 'gamma': 0.3844591654501174, 'lambda': 1.8944882998312318}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:27:13,171] Trial 289 finished with value: 0.9261168384879727 and parameters: {'booster': 'gbtree', 'eta': 0.8116085038972228, 'learning_rate': 0.07488155057820083, 'n_estimators': 560, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6733910234929583, 'colsample_bytree': 0.7212103635099429, 'gamma': 0.36046780200753403, 'lambda': 2.0986361296563163}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:27:35,690] Trial 290 finished with value: 0.9288659793814434 and parameters: {'booster': 'gbtree', 'eta': 0.9984422022806327, 'learning_rate': 0.02039764618041061, 'n_estimators': 787, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6435127302366992, 'colsample_bytree': 0.7650702805308414, 'gamma': 0.24535075692253577, 'lambda': 2.6418166757096646}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:29:09,545] Trial 291 finished with value: 0.927491408934708 and parameters: {'booster': 'gbtree', 'eta': 0.1627797472861298, 'learning_rate': 0.11909420421349257, 'n_estimators': 618, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.618424162768161, 'colsample_bytree': 0.8954891589260625, 'gamma': 0.2748146646805478, 'lambda': 1.7284739217312115}. Best is trial 197 with value: 0.9333333333333335.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:29:09] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:29:38] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:30:08] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:30:37] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:31:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:31:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:31:56] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:32:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:32:48] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:33:14] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:33:39] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:34:05] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:34:30] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:34:37] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:34:37] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "colsample_bytree", "gamma", "max_depth", "min_child_weight", "subsample" } are not used.

  warnings.warn(smsg, UserWarning)
[I 2024-06-06 17:34:37,901] Trial 292 finished with value: 0.8068728522336772 and parameters: {'booster': 'gblinear', 'eta': 0.6977383814787442, 'learning_rate': 0.03169989547088644, 'n_estimators': 645, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6911278564369405, 'colsample_bytree': 0.855004088693001, 'gamma': 0.22783459910593823, 'lambda': 1.4130340208929297}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:34:48,071] Trial 293 finished with value: 0.9237113402061857 and parameters: {'booster': 'gbtree', 'eta': 0.6202968677786153, 'learning_rate': 0.10295490106447279, 'n_estimators': 692, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6546023334179497, 'colsample_bytree': 0.9578980450348306, 'gamma': 0.3112264189017475, 'lambda': 1.5572372345027057}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:35:19,706] Trial 294 finished with value: 0.9278350515463919 and parameters: {'booster': 'gbtree', 'eta': 0.4815873516779511, 'learning_rate': 0.04661966022673922, 'n_estimators': 980, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6334944847035744, 'colsample_bytree': 0.7993117698490292, 'gamma': 0.2619289466695603, 'lambda': 1.8571954002870295}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:35:31,332] Trial 295 finished with value: 0.9319587628865981 and parameters: {'booster': 'gbtree', 'eta': 0.2419423092774619, 'learning_rate': 0.06128632479051315, 'n_estimators': 500, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.6645868816420384, 'colsample_bytree': 0.9149752753284115, 'gamma': 0.10282822550884062, 'lambda': 1.9561014444455485}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:35:43,328] Trial 296 finished with value: 0.9271477663230242 and parameters: {'booster': 'gbtree', 'eta': 0.23554993962659054, 'learning_rate': 0.06280849192136942, 'n_estimators': 508, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6053629235216347, 'colsample_bytree': 0.9114247745265492, 'gamma': 0.08839294108993184, 'lambda': 2.040440614890962}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:35:57,543] Trial 297 finished with value: 0.9319587628865981 and parameters: {'booster': 'gbtree', 'eta': 0.23032786208360764, 'learning_rate': 0.05518937220914406, 'n_estimators': 526, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.648981597427354, 'colsample_bytree': 0.9033355859980938, 'gamma': 0.08666607872684894, 'lambda': 1.9601489079684533}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:36:11,874] Trial 298 finished with value: 0.9319587628865981 and parameters: {'booster': 'gbtree', 'eta': 0.20444133638878115, 'learning_rate': 0.05206952382359369, 'n_estimators': 502, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6426391434861191, 'colsample_bytree': 0.999950180077893, 'gamma': 0.08037306721852522, 'lambda': 2.8709460521250745}. Best is trial 197 with value: 0.9333333333333335.
[I 2024-06-06 17:36:22,630] Trial 299 finished with value: 0.9302405498281788 and parameters: {'booster': 'gbtree', 'eta': 0.2038335582470076, 'learning_rate': 0.11207052837177796, 'n_estimators': 504, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6432722036597367, 'colsample_bytree': 0.9170769076697923, 'gamma': 0.0877839023920171, 'lambda': 2.854054713427398}. Best is trial 197 with value: 0.9333333333333335.
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:36:22] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "class_weight" } are not used.

  warnings.warn(smsg, UserWarning)
/home/fazzarello/miniforge3/envs/celltype_classification/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [17:36:23] WARNING: /workspace/src/learner.cc:742: 
Parameters: { "class_weight" } are not used.

  warnings.warn(smsg, UserWarning)
